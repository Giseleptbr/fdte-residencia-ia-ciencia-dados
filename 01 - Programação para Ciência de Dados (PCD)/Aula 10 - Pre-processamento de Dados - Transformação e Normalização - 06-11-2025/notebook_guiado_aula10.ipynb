{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g53AVTpccpDy"
      },
      "source": [
        "# Aula 10 - Pré-processamento de Dados: Transformação e Normalização\n",
        "\n",
        "**Objetivo:** Aprender técnicas de transformação de dados para análise exploratória avançada\n",
        "\n",
        "**Dataset:** Telco Customer Churn (previsão de cancelamento de clientes)\n",
        "\n",
        "---\n",
        "\n",
        "## Agenda\n",
        "\n",
        "1. **Feature Engineering** - Criar variáveis derivadas úteis\n",
        "2. **Encoding** - Converter categorias em números\n",
        "3. **Normalização** - Ajustar escalas para comparabilidade\n",
        "4. **Pipeline Completo** - Integrar todas as transformações\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwEbNEfhcpDz"
      },
      "source": [
        "## Setup Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm0ia4cXcpD0"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Configurações do pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ6UP79rcpD0"
      },
      "source": [
        "## Carregar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ei2c9y5cpD0"
      },
      "outputs": [],
      "source": [
        "# Carregar dados\n",
        "url = 'https://raw.githubusercontent.com/marvin-rubia/Churn-Analysis-Prediction/main/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "print(\"=== INFORMAÇÕES DO DATASET ===\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nColunas: {df.columns.tolist()}\")\n",
        "print(f\"\\nTipos de dados:\")\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "# Primeiras linhas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjQPXoakcpD1"
      },
      "source": [
        "## Entendimento Rápido dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLWvAtAscpD1"
      },
      "outputs": [],
      "source": [
        "# Estatísticas descritivas - numéricas\n",
        "print(\"=== VARIÁVEIS NUMÉRICAS ===\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37L0WnZacpD1"
      },
      "outputs": [],
      "source": [
        "# Estatísticas descritivas - categóricas\n",
        "print(\"=== VARIÁVEIS CATEGÓRICAS ===\")\n",
        "df.describe(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9_PrZLwcpD1"
      },
      "outputs": [],
      "source": [
        "# Distribuição do target (Churn)\n",
        "print(\"=== DISTRIBUIÇÃO DO TARGET (CHURN) ===\")\n",
        "print(df['Churn'].value_counts())\n",
        "print(f\"\\nTaxa de Churn: {(df['Churn'] == 'Yes').mean()*100:.2f}%\")\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "df['Churn'].value_counts().plot(kind='bar', ax=ax, color=['skyblue', 'salmon'])\n",
        "ax.set_title('Distribuição de Churn', fontsize=14)\n",
        "ax.set_xlabel('Churn')\n",
        "ax.set_ylabel('Quantidade')\n",
        "ax.set_xticklabels(['No', 'Yes'], rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sngPtjFTcpD1"
      },
      "source": [
        "## Tratamento Básico\n",
        "\n",
        "Antes de começar as transformações, vamos fazer alguns tratamentos básicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWMk0QoScpD1"
      },
      "outputs": [],
      "source": [
        "# Converter TotalCharges para numérico (pode ter strings vazias)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Verificar missing values\n",
        "print(\"=== MISSING VALUES ===\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0])\n",
        "\n",
        "# Preencher TotalCharges missing com MonthlyCharges (clientes novos)\n",
        "df['TotalCharges'].fillna(df['MonthlyCharges'], inplace=True)\n",
        "\n",
        "print(\"\\n✓ Tratamento básico completo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv_mZ1CZcpD2"
      },
      "source": [
        "---\n",
        "\n",
        "# BLOCO 1: Feature Engineering\n",
        "\n",
        "**Objetivo:** Criar novas variáveis (features) a partir das existentes para revelar padrões ocultos.\n",
        "\n",
        "**Estratégia:**\n",
        "1. Criar feature\n",
        "2. Validar através de análise exploratória\n",
        "3. Verificar correlação com Churn\n",
        "4. Decidir se mantém ou descarta\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzl8iTOkcpD2"
      },
      "source": [
        "## Técnica 1: Operações Aritméticas Simples\n",
        "\n",
        "**Feature:** Gasto médio mensal (AvgMonthlySpend)\n",
        "\n",
        "**Raciocínio:** TotalCharges / tenure revela padrão de gasto mais claramente que valores absolutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3-OCTURcpD2"
      },
      "outputs": [],
      "source": [
        "# Criar feature\n",
        "df['AvgMonthlySpend'] = df['TotalCharges'] / df['tenure']\n",
        "\n",
        "# Tratar casos especiais (tenure = 0)\n",
        "df['AvgMonthlySpend'] = df['AvgMonthlySpend'].replace([np.inf, -np.inf], np.nan)\n",
        "df.loc[df['tenure'] == 0, 'AvgMonthlySpend'] = df.loc[df['tenure'] == 0, 'MonthlyCharges']\n",
        "\n",
        "print(\"=== FEATURE CRIADA: AvgMonthlySpend ===\")\n",
        "print(df['AvgMonthlySpend'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MspQoQ3ucpD2"
      },
      "outputs": [],
      "source": [
        "# Validação: Comparar por Churn\n",
        "print(\"=== COMPARAÇÃO POR CHURN ===\")\n",
        "comparison = df.groupby('Churn')['AvgMonthlySpend'].describe()\n",
        "print(comparison)\n",
        "\n",
        "# Visualizar\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Boxplot\n",
        "sns.boxplot(data=df, x='Churn', y='AvgMonthlySpend', ax=axes[0])\n",
        "axes[0].set_title('Gasto Médio Mensal por Churn')\n",
        "axes[0].set_ylabel('Gasto Médio Mensal (R$)')\n",
        "\n",
        "# Histogramas sobrepostos\n",
        "df[df['Churn']=='No']['AvgMonthlySpend'].hist(bins=30, alpha=0.5, label='No Churn', ax=axes[1], color='skyblue')\n",
        "df[df['Churn']=='Yes']['AvgMonthlySpend'].hist(bins=30, alpha=0.5, label='Churn', ax=axes[1], color='salmon')\n",
        "axes[1].set_xlabel('Gasto Médio Mensal')\n",
        "axes[1].set_title('Distribuição por Grupo')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Clientes com churn têm gasto médio mensal ligeiramente maior\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tn7f_3lcpD2"
      },
      "source": [
        "## Técnica 2: Diferenças entre Variáveis\n",
        "\n",
        "**Feature:** Diferença entre gasto atual e média histórica (ChargeDiff)\n",
        "\n",
        "**Raciocínio:** Aumento recente no preço pode indicar insatisfação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PMKaEG4cpD3"
      },
      "outputs": [],
      "source": [
        "# Criar feature\n",
        "df['ChargeDiff'] = df['MonthlyCharges'] - df['AvgMonthlySpend']\n",
        "\n",
        "print(\"=== FEATURE CRIADA: ChargeDiff ===\")\n",
        "print(df['ChargeDiff'].describe())\n",
        "\n",
        "print(\"\\n=== INTERPRETAÇÃO ===\")\n",
        "print(\"ChargeDiff > 0: Gasto atual maior que média (possível aumento recente)\")\n",
        "print(\"ChargeDiff < 0: Gasto atual menor que média (possível desconto ou redução)\")\n",
        "print(\"ChargeDiff ≈ 0: Gasto estável\")\n",
        "\n",
        "# Analisar por churn\n",
        "print(\"\\n=== MÉDIA POR CHURN ===\")\n",
        "print(df.groupby('Churn')['ChargeDiff'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBYlFLOYcpD3"
      },
      "source": [
        "## Técnica 3: Razões e Proporções\n",
        "\n",
        "**Feature:** Proporção do tempo como cliente (TenureRatio)\n",
        "\n",
        "**Raciocínio:** Normalizar tenure facilita interpretação e comparação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQDtXYgRcpD3"
      },
      "outputs": [],
      "source": [
        "# Criar feature\n",
        "max_tenure = df['tenure'].max()\n",
        "df['TenureRatio'] = df['tenure'] / max_tenure\n",
        "\n",
        "print(\"=== FEATURE CRIADA: TenureRatio ===\")\n",
        "print(f\"Range: [{df['TenureRatio'].min():.2f}, {df['TenureRatio'].max():.2f}]\")\n",
        "print(df['TenureRatio'].describe())\n",
        "\n",
        "# Criar categorias baseadas no ratio\n",
        "df['TenureCategory'] = pd.cut(df['TenureRatio'],\n",
        "                               bins=[0, 0.33, 0.66, 1.0],\n",
        "                               labels=['Novo', 'Médio', 'Veterano'])\n",
        "\n",
        "print(\"\\n=== DISTRIBUIÇÃO POR CATEGORIA ===\")\n",
        "print(pd.crosstab(df['TenureCategory'], df['Churn'], normalize='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMk6oBjpcpD3"
      },
      "source": [
        "## Técnica 4: Binning (Discretização)\n",
        "\n",
        "**Feature:** MonthlyCharges em faixas de preço\n",
        "\n",
        "**Raciocínio:** Agrupar em faixas facilita análise e visualização de padrões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpYYF_6kcpD3"
      },
      "outputs": [],
      "source": [
        "# Método 1: Bins com larguras iguais\n",
        "df['ChargesBin_Equal'] = pd.cut(df['MonthlyCharges'],\n",
        "                                 bins=5,\n",
        "                                 labels=['Muito Baixo', 'Baixo', 'Médio', 'Alto', 'Muito Alto'])\n",
        "\n",
        "# Método 2: Quantis (mesma quantidade em cada bin)\n",
        "df['ChargesBin_Quantile'] = pd.qcut(df['MonthlyCharges'],\n",
        "                                     q=5,\n",
        "                                     labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'],\n",
        "                                     duplicates='drop')\n",
        "\n",
        "print(\"=== BINNING CRIADO ===\")\n",
        "print(\"\\nDistribuição - Bins Iguais:\")\n",
        "print(df['ChargesBin_Equal'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nDistribuição - Quantis:\")\n",
        "print(df['ChargesBin_Quantile'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDa4hHspcpD3"
      },
      "outputs": [],
      "source": [
        "# Analisar churn por faixa de preço\n",
        "print(\"=== CHURN RATE POR FAIXA ===\")\n",
        "churn_by_bin = df.groupby('ChargesBin_Equal')['Churn'].apply(\n",
        "    lambda x: (x == 'Yes').mean()\n",
        ")\n",
        "print(churn_by_bin)\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "churn_by_bin.plot(kind='bar', color='coral', ax=ax)\n",
        "ax.set_title('Taxa de Churn por Faixa de Preço', fontsize=14)\n",
        "ax.set_ylabel('Taxa de Churn')\n",
        "ax.set_xlabel('Faixa de MonthlyCharges')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "ax.axhline(y=(df['Churn']=='Yes').mean(), color='red', linestyle='--', alpha=0.5, label='Média geral')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Churn aumenta significativamente em faixas de preço mais alto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYOLQL5TcpD3"
      },
      "source": [
        "## Técnica 5: Agregação - Contar Serviços\n",
        "\n",
        "**Feature:** Total de serviços adicionais (TotalServices)\n",
        "\n",
        "**Raciocínio:** Clientes com mais serviços podem estar mais \"engajados\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdOsG3S_cpD4"
      },
      "outputs": [],
      "source": [
        "# Lista de colunas de serviços\n",
        "service_cols = [\n",
        "    'PhoneService', 'MultipleLines',\n",
        "    'InternetService', 'OnlineSecurity',\n",
        "    'OnlineBackup', 'DeviceProtection',\n",
        "    'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
        "]\n",
        "\n",
        "# Contar serviços ativos\n",
        "df['TotalServices'] = 0\n",
        "for col in service_cols:\n",
        "    # Adiciona 1 se não for \"No\" ou \"No internet service\" ou \"No phone service\"\n",
        "    df['TotalServices'] += (~df[col].isin(['No', 'No internet service', 'No phone service'])).astype(int)\n",
        "\n",
        "print(\"=== FEATURE CRIADA: TotalServices ===\")\n",
        "print(df['TotalServices'].describe())\n",
        "\n",
        "print(\"\\n=== DISTRIBUIÇÃO ===\")\n",
        "print(df['TotalServices'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqcOIMD1cpD4"
      },
      "outputs": [],
      "source": [
        "# Analisar relação com Churn\n",
        "print(\"=== MÉDIA DE SERVIÇOS POR CHURN ===\")\n",
        "print(df.groupby('Churn')['TotalServices'].mean())\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "pd.crosstab(df['TotalServices'], df['Churn']).plot(kind='bar', ax=ax)\n",
        "ax.set_title('Distribuição de Churn por Total de Serviços', fontsize=14)\n",
        "ax.set_xlabel('Número de Serviços')\n",
        "ax.set_ylabel('Quantidade de Clientes')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "ax.legend(['No Churn', 'Churn'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Interessante: parece haver padrão em U - baixo e alto número de serviços associados a mais churn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzn3YiR_cpD4"
      },
      "source": [
        "## Técnica 6: Flags Booleanas\n",
        "\n",
        "**Features:** Indicadores binários (0/1) para condições específicas\n",
        "\n",
        "**Raciocínio:** Simplificar análise de combinações importantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOEAtd0wcpD4"
      },
      "outputs": [],
      "source": [
        "# Criar flags\n",
        "df['HasInternet'] = (df['InternetService'] != 'No').astype(int)\n",
        "df['HasPhone'] = (df['PhoneService'] == 'Yes').astype(int)\n",
        "df['SeniorWithDependents'] = ((df['SeniorCitizen'] == 1) & (df['Dependents'] == 'Yes')).astype(int)\n",
        "df['IsPremium'] = ((df['TotalServices'] >= 6) & (df['Contract'].isin(['One year', 'Two year']))).astype(int)\n",
        "\n",
        "print(\"=== FLAGS CRIADAS ===\")\n",
        "flags = ['HasInternet', 'HasPhone', 'SeniorWithDependents', 'IsPremium']\n",
        "\n",
        "for flag in flags:\n",
        "    count = df[flag].sum()\n",
        "    pct = df[flag].mean() * 100\n",
        "    print(f\"{flag}: {count} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0LM0RZdcpD4"
      },
      "outputs": [],
      "source": [
        "# Analisar impacto no Churn\n",
        "print(\"=== ANÁLISE DE FLAGS vs CHURN ===\\n\")\n",
        "\n",
        "for flag in flags:\n",
        "    print(f\"\\n--- {flag} ---\")\n",
        "\n",
        "    # Taxa de churn por flag\n",
        "    churn_rate = df.groupby(flag)['Churn'].apply(lambda x: (x == 'Yes').mean())\n",
        "    print(\"Taxa de Churn:\")\n",
        "    print(churn_rate)\n",
        "\n",
        "    # Diferença\n",
        "    if len(churn_rate) == 2:\n",
        "        diff = churn_rate[1] - churn_rate[0]\n",
        "        print(f\"Diferença: {diff*100:.1f} pontos percentuais\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJnUgyqIcpD4"
      },
      "source": [
        "## Técnica 7: Interações entre Variáveis\n",
        "\n",
        "**Features:** Combinações que capturam efeitos sinérgicos\n",
        "\n",
        "**Raciocínio:** Algumas combinações têm efeito maior que variáveis isoladas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUGdfmYRcpD4"
      },
      "outputs": [],
      "source": [
        "# Criar interações\n",
        "# Interação 1: Contrato curto + Preço alto (hipótese: combinação perigosa)\n",
        "df['ShortContract_HighPrice'] = (\n",
        "    (df['Contract'] == 'Month-to-month') &\n",
        "    (df['MonthlyCharges'] > df['MonthlyCharges'].quantile(0.75))\n",
        ").astype(int)\n",
        "\n",
        "# Interação 2: Idoso sem segurança online\n",
        "df['Senior_NoSecurity'] = (\n",
        "    (df['SeniorCitizen'] == 1) &\n",
        "    (df['OnlineSecurity'] == 'No')\n",
        ").astype(int)\n",
        "\n",
        "# Interação 3: Fibra + Streaming (usuário power)\n",
        "df['FiberStreamer'] = (\n",
        "    (df['InternetService'] == 'Fiber optic') &\n",
        "    ((df['StreamingTV'] == 'Yes') | (df['StreamingMovies'] == 'Yes'))\n",
        ").astype(int)\n",
        "\n",
        "print(\"=== INTERAÇÕES CRIADAS ===\")\n",
        "interactions = ['ShortContract_HighPrice', 'Senior_NoSecurity', 'FiberStreamer']\n",
        "\n",
        "for inter in interactions:\n",
        "    count = df[inter].sum()\n",
        "    pct = df[inter].mean() * 100\n",
        "    print(f\"{inter}: {count} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5dLPDcMcpD5"
      },
      "outputs": [],
      "source": [
        "# Analisar impacto das interações\n",
        "print(\"=== ANÁLISE DE INTERAÇÕES ===\\n\")\n",
        "\n",
        "for interaction in interactions:\n",
        "    print(f\"\\n--- {interaction} ---\")\n",
        "\n",
        "    # Crosstab com Churn\n",
        "    ct = pd.crosstab(df[interaction], df['Churn'], normalize='index')\n",
        "    print(ct)\n",
        "\n",
        "    # Taxa de churn quando interação = 1\n",
        "    churn_rate_with = df[df[interaction] == 1]['Churn'].apply(lambda x: 1 if x == 'Yes' else 0).mean()\n",
        "    overall_rate = (df['Churn'] == 'Yes').mean()\n",
        "\n",
        "    print(f\"\\nChurn Rate com {interaction}=1: {churn_rate_with*100:.1f}%\")\n",
        "    print(f\"Churn Rate geral: {overall_rate*100:.1f}%\")\n",
        "    print(f\"Diferença: {(churn_rate_with - overall_rate)*100:.1f} pontos percentuais\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jTprniocpD5"
      },
      "source": [
        "## Técnica 8: Percentis e Rankings\n",
        "\n",
        "**Feature:** Posição relativa no dataset\n",
        "\n",
        "**Raciocínio:** Às vezes importa mais a posição relativa que o valor absoluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv6bf_-icpD5"
      },
      "outputs": [],
      "source": [
        "# Criar features de ranking\n",
        "df['TotalCharges_Percentile'] = df['TotalCharges'].rank(pct=True) * 100\n",
        "df['TotalCharges_Rank'] = df['TotalCharges'].rank(ascending=False)\n",
        "\n",
        "# Categorizar por percentil\n",
        "df['ChargesLevel'] = pd.cut(df['TotalCharges_Percentile'],\n",
        "                             bins=[0, 25, 50, 75, 100],\n",
        "                             labels=['Bottom 25%', 'Q2', 'Q3', 'Top 25%'])\n",
        "\n",
        "print(\"=== DISTRIBUIÇÃO POR NÍVEL ===\")\n",
        "print(df['ChargesLevel'].value_counts())\n",
        "\n",
        "# Analisar churn por nível\n",
        "print(\"\\n=== CHURN POR NÍVEL ===\")\n",
        "print(pd.crosstab(df['ChargesLevel'], df['Churn'], normalize='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMY8WJxhcpD5"
      },
      "source": [
        "## Técnica 9: Z-Score para Detecção de Anomalias\n",
        "\n",
        "**Feature:** Identificar valores extremos (outliers)\n",
        "\n",
        "**Raciocínio:** Clientes com comportamento atípico podem ter padrão diferente de churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_kNTNsicpD5"
      },
      "outputs": [],
      "source": [
        "# Calcular Z-scores\n",
        "df['MonthlyCharges_Zscore'] = stats.zscore(df['MonthlyCharges'])\n",
        "\n",
        "# Flag para outliers (|Z| > 3)\n",
        "df['IsOutlier_Charges'] = (abs(df['MonthlyCharges_Zscore']) > 3).astype(int)\n",
        "\n",
        "print(\"=== OUTLIERS IDENTIFICADOS ===\")\n",
        "print(f\"Total de outliers: {df['IsOutlier_Charges'].sum()}\")\n",
        "print(f\"Percentual: {df['IsOutlier_Charges'].mean()*100:.2f}%\")\n",
        "\n",
        "# Analisar outliers\n",
        "print(\"\\n=== CHURN ENTRE OUTLIERS ===\")\n",
        "print(pd.crosstab(df['IsOutlier_Charges'], df['Churn'], normalize='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIDV_p5ZcpD5"
      },
      "source": [
        "## Técnica 10: Features Baseadas em Conhecimento do Domínio\n",
        "\n",
        "**Features:** Perfis de risco baseados em expertise\n",
        "\n",
        "**Raciocínio:** Combinar múltiplos fatores que especialistas identificam como importantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kiu8mPoocpD5"
      },
      "outputs": [],
      "source": [
        "# Feature: High Risk Profile\n",
        "df['HighRiskProfile'] = (\n",
        "    (df['Contract'] == 'Month-to-month') &  # Sem compromisso\n",
        "    (df['tenure'] < 12) &                    # Cliente novo\n",
        "    (df['TotalServices'] <= 2) &             # Poucos serviços\n",
        "    (df['PaymentMethod'] == 'Electronic check')  # Método menos estável\n",
        ").astype(int)\n",
        "\n",
        "# Feature: Value Customer\n",
        "df['ValueCustomer'] = (\n",
        "    (df['Contract'].isin(['One year', 'Two year'])) &  # Contrato longo\n",
        "    (df['TotalServices'] >= 4) &                       # Muitos serviços\n",
        "    (df['tenure'] > 24) &                              # Cliente antigo\n",
        "    (df['MonthlyCharges'] > df['MonthlyCharges'].median())  # Gasto alto\n",
        ").astype(int)\n",
        "\n",
        "print(\"=== PERFIS CRIADOS ===\")\n",
        "profiles = ['HighRiskProfile', 'ValueCustomer']\n",
        "\n",
        "for profile in profiles:\n",
        "    count = df[profile].sum()\n",
        "    pct = df[profile].mean() * 100\n",
        "    print(f\"{profile}: {count} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grg7JdQpcpD5"
      },
      "outputs": [],
      "source": [
        "# Validar perfis\n",
        "print(\"=== ANÁLISE DE PERFIS ===\\n\")\n",
        "\n",
        "for profile in profiles:\n",
        "    print(f\"\\n--- {profile} ---\")\n",
        "\n",
        "    # Churn rate\n",
        "    churn_rate = df[df[profile] == 1]['Churn'].apply(lambda x: 1 if x == 'Yes' else 0).mean()\n",
        "    baseline = (df['Churn'] == 'Yes').mean()\n",
        "\n",
        "    print(f\"Churn Rate: {churn_rate*100:.1f}%\")\n",
        "    print(f\"Baseline: {baseline*100:.1f}%\")\n",
        "    print(f\"Diferença: {(churn_rate - baseline)*100:.1f} pontos percentuais\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNRFOEkNcpD6"
      },
      "source": [
        "## Resumo: Features Criadas\n",
        "\n",
        "Vamos listar todas as features que criamos e suas correlações com Churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFJL2GYZcpD6"
      },
      "outputs": [],
      "source": [
        "# Listar features criadas\n",
        "created_features = [\n",
        "    'AvgMonthlySpend', 'ChargeDiff', 'TenureRatio',\n",
        "    'TotalServices', 'HasInternet', 'HasPhone',\n",
        "    'SeniorWithDependents', 'IsPremium',\n",
        "    'ShortContract_HighPrice', 'Senior_NoSecurity', 'FiberStreamer',\n",
        "    'TotalCharges_Percentile', 'IsOutlier_Charges',\n",
        "    'HighRiskProfile', 'ValueCustomer'\n",
        "]\n",
        "\n",
        "print(f\"=== TOTAL DE FEATURES CRIADAS: {len(created_features)} ===\")\n",
        "print(\"\\nFeatures:\")\n",
        "for feat in created_features:\n",
        "    print(f\"  - {feat}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2FW4_uicpD6"
      },
      "outputs": [],
      "source": [
        "# Criar target binário para correlações\n",
        "df['Churn_binary'] = (df['Churn'] == 'Yes').astype(int)\n",
        "\n",
        "# Calcular correlações com Churn\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "correlations = df[numeric_features].corr()['Churn_binary'].drop('Churn_binary')\n",
        "correlations_abs = correlations.abs().sort_values(ascending=False)\n",
        "\n",
        "print(\"=== TOP 15 FEATURES MAIS CORRELACIONADAS COM CHURN ===\")\n",
        "print(correlations_abs.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AP9Bq0-cpD6"
      },
      "outputs": [],
      "source": [
        "# Visualizar top correlações\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "top_20 = correlations_abs.head(20)\n",
        "top_20.plot(kind='barh', ax=ax, color='steelblue')\n",
        "ax.set_xlabel('Correlação Absoluta com Churn')\n",
        "ax.set_title('Top 20 Features Mais Correlacionadas com Churn', fontsize=14)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Feature Engineering completo!\")\n",
        "print(\"✓ Próximo: Encoding de variáveis categóricas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTYycptCcpD6"
      },
      "source": [
        "---\n",
        "\n",
        "**Checkpoint:** Salvar progresso antes de continuar para o Encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5hcmIaFcpD6"
      },
      "outputs": [],
      "source": [
        "# Salvar dataset com features criadas\n",
        "df.to_csv('telco_churn_with_features.csv', index=False)\n",
        "print(\"✓ Dataset salvo: telco_churn_with_features.csv\")\n",
        "print(f\"Shape atual: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmO0bzADcpD7"
      },
      "source": [
        "# Aula 10 - PARTE 2: Encoding e Normalização\n",
        "\n",
        "**Continuação da transformação de dados**\n",
        "\n",
        "Nesta parte:\n",
        "- **Bloco 2:** Encoding de variáveis categóricas\n",
        "- **Bloco 3:** Normalização e padronização\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kj-F9uacpD7"
      },
      "source": [
        "## Setup (caso esteja começando daqui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97kB-edccpD7"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configurações\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Setup completo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9CgfAGhcpD7"
      },
      "outputs": [],
      "source": [
        "# Carregar dados (com features criadas na Parte 1)\n",
        "df = pd.read_csv('telco_churn_with_features.csv')\n",
        "\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\n✓ Dataset carregado com {df.shape[1]} colunas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-RX6Ed5cpD7"
      },
      "source": [
        "---\n",
        "\n",
        "# BLOCO 2: Encoding de Variáveis Categóricas\n",
        "\n",
        "**Objetivo:** Converter todas as variáveis categóricas em numéricas para permitir análises quantitativas.\n",
        "\n",
        "**Estratégias:**\n",
        "1. **Label Encoding** - Para ordinais (variáveis com ordem natural)\n",
        "2. **One-Hot Encoding** - Para nominais (variáveis sem ordem)\n",
        "3. **Binary Encoding** - Para binárias (Yes/No, True/False)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHCBQRpOcpD7"
      },
      "source": [
        "## Identificar Tipos de Variáveis Categóricas\n",
        "\n",
        "Primeiro, vamos classificar nossas variáveis categóricas por tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGV6BuEVcpD7"
      },
      "outputs": [],
      "source": [
        "# Listar variáveis categóricas\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Remover IDs e target original\n",
        "categorical_cols = [c for c in categorical_cols if c not in ['customerID', 'Churn']]\n",
        "\n",
        "print(\"=== VARIÁVEIS CATEGÓRICAS PARA ENCODING ===\")\n",
        "print(f\"\\nTotal: {len(categorical_cols)}\\n\")\n",
        "\n",
        "for col in categorical_cols:\n",
        "    unique_vals = df[col].nunique()\n",
        "    print(f\"{col}: {unique_vals} valores únicos\")\n",
        "    print(f\"  Valores: {df[col].unique()[:5].tolist()}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDNVmLaVcpD7"
      },
      "source": [
        "## Classificação Manual das Variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO5iWoQjcpD8"
      },
      "outputs": [],
      "source": [
        "# Classificar por tipo\n",
        "ordinal_vars = {\n",
        "    'Contract': {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
        "}\n",
        "\n",
        "binary_vars = [\n",
        "    'gender', 'Partner', 'Dependents',\n",
        "    'PhoneService', 'PaperlessBilling'\n",
        "]\n",
        "\n",
        "nominal_vars = [\n",
        "    'PaymentMethod', 'InternetService'\n",
        "]\n",
        "\n",
        "# Variáveis com \"No service\" (tratamento especial)\n",
        "service_with_no = [\n",
        "    'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
        "    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
        "]\n",
        "\n",
        "print(\"=== CLASSIFICAÇÃO ===\")\n",
        "print(f\"\\nOrdinais: {len(ordinal_vars)}\")\n",
        "print(f\"Binárias: {len(binary_vars)}\")\n",
        "print(f\"Nominais: {len(nominal_vars)}\")\n",
        "print(f\"Serviços (com 'No service'): {len(service_with_no)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1340x4ZcpD8"
      },
      "source": [
        "## 1. Label Encoding - Variáveis Ordinais\n",
        "\n",
        "**Contract** é ordinal porque tem ordem natural de compromisso: Month-to-month < One year < Two year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSNGjfvxcpD8"
      },
      "outputs": [],
      "source": [
        "# Label Encoding manual (preserva ordem)\n",
        "print(\"=== LABEL ENCODING: Contract ===\")\n",
        "\n",
        "contract_mapping = ordinal_vars['Contract']\n",
        "df['Contract_encoded'] = df['Contract'].map(contract_mapping)\n",
        "\n",
        "print(\"\\nMapeamento:\")\n",
        "for category, code in contract_mapping.items():\n",
        "    print(f\"  {category} → {code}\")\n",
        "\n",
        "print(\"\\nVerificação:\")\n",
        "print(df[['Contract', 'Contract_encoded']].drop_duplicates().sort_values('Contract_encoded'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnjJsy1ccpD8"
      },
      "outputs": [],
      "source": [
        "# Validar: correlação com Churn\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "corr, pval = pearsonr(df['Contract_encoded'], df['Churn_binary'])\n",
        "print(\"=== VALIDAÇÃO: Contract_encoded vs Churn ===\")\n",
        "print(f\"Correlação: {corr:.3f} (p-value: {pval:.4f})\")\n",
        "\n",
        "# Visualizar\n",
        "churn_by_contract = df.groupby('Contract_encoded')['Churn'].apply(lambda x: (x == 'Yes').mean())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "churn_by_contract.plot(kind='bar', color='salmon', ax=ax)\n",
        "ax.set_title('Taxa de Churn por Tipo de Contrato', fontsize=14)\n",
        "ax.set_xlabel('Contract (0=Month, 1=1yr, 2=2yr)')\n",
        "ax.set_ylabel('Taxa de Churn')\n",
        "ax.set_xticklabels(['Month-to-month', 'One year', 'Two year'], rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Correlação negativa forte: contratos mais longos → menos churn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWjP3lSUcpD8"
      },
      "source": [
        "## 2. Binary Encoding - Variáveis Binárias (Yes/No)\n",
        "\n",
        "Para variáveis com apenas 2 valores, usamos 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fofz-Mh3cpD8"
      },
      "outputs": [],
      "source": [
        "# Encoding de binárias\n",
        "print(\"=== BINARY ENCODING ===\")\n",
        "\n",
        "for col in binary_vars:\n",
        "    # Método 1: Operador booleano (mais conciso)\n",
        "    df[f'{col}_encoded'] = (df[col] == 'Yes').astype(int)\n",
        "    # Para gender: Male=1, Female=0\n",
        "    if col == 'gender':\n",
        "        df[f'{col}_encoded'] = (df[col] == 'Male').astype(int)\n",
        "\n",
        "    print(f\"✓ {col} encoded\")\n",
        "\n",
        "# SeniorCitizen já é 0/1\n",
        "df['SeniorCitizen_encoded'] = df['SeniorCitizen']\n",
        "print(\"✓ SeniorCitizen (já numérico)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCnHJMRAcpD8"
      },
      "outputs": [],
      "source": [
        "# Verificar encodings\n",
        "print(\"=== VERIFICAÇÃO DOS ENCODINGS ===\")\n",
        "\n",
        "for col in binary_vars:\n",
        "    encoded_col = f'{col}_encoded'\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[[col, encoded_col]].drop_duplicates().sort_values(encoded_col))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocPs08SqcpD9"
      },
      "source": [
        "## 3. Tratamento Especial - Variáveis com \"No Service\"\n",
        "\n",
        "Algumas variáveis têm 3 valores: Yes, No, No internet/phone service.\n",
        "\n",
        "Vamos criar variável binária: tem o serviço (Yes) ou não tem (No ou No service)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_PdJa2LcpD9"
      },
      "outputs": [],
      "source": [
        "# Encoding de serviços\n",
        "print(\"=== ENCODING: Variáveis de Serviço ===\")\n",
        "\n",
        "for col in service_with_no:\n",
        "    # 1 se 'Yes', 0 caso contrário\n",
        "    df[f'{col}_encoded'] = (df[col] == 'Yes').astype(int)\n",
        "    print(f\"✓ {col} encoded\")\n",
        "\n",
        "print(\"\\n✓ Todas as variáveis de serviço encodadas como binárias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdreMQCScpD9"
      },
      "outputs": [],
      "source": [
        "# Exemplo de verificação\n",
        "print(\"=== EXEMPLO: OnlineSecurity ===\")\n",
        "print(df[['OnlineSecurity', 'OnlineSecurity_encoded']].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhz3YB6JcpD9"
      },
      "source": [
        "## 4. One-Hot Encoding - Variáveis Nominais\n",
        "\n",
        "Para variáveis sem ordem natural, criamos colunas binárias para cada categoria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyszH6imcpD9"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding\n",
        "print(\"=== ONE-HOT ENCODING ===\")\n",
        "\n",
        "print(\"\\nANTES do One-Hot:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "\n",
        "# Aplicar One-Hot\n",
        "df = pd.get_dummies(df,\n",
        "                    columns=nominal_vars,\n",
        "                    prefix=nominal_vars,\n",
        "                    drop_first=True,  # Evitar multicolinearidade\n",
        "                    dtype=int)\n",
        "\n",
        "print(\"\\nDEPOIS do One-Hot:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "\n",
        "# Listar novas colunas criadas\n",
        "new_cols = [c for c in df.columns if any(nom in c for nom in nominal_vars)]\n",
        "print(f\"\\nColunas criadas ({len(new_cols)}):\")\n",
        "for col in new_cols:\n",
        "    print(f\"  - {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4a1jcWfcpD9"
      },
      "source": [
        "### Por que drop_first=True?\n",
        "\n",
        "Com 3 categorias de InternetService:\n",
        "- Se DSL=0 e Fiber=0, então necessariamente No=1\n",
        "- Informação redundante (multicolinearidade perfeita)\n",
        "- drop_first=True remove primeira categoria (vira referência)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LejK9pptcpD9"
      },
      "outputs": [],
      "source": [
        "# Demonstrar drop_first\n",
        "print(\"=== DEMONSTRAÇÃO: drop_first ===\")\n",
        "\n",
        "# Recarregar dados para exemplo\n",
        "df_exemplo = pd.read_csv('telco_churn_with_features.csv')\n",
        "\n",
        "# Sem drop_first\n",
        "dummy_full = pd.get_dummies(df_exemplo['InternetService'], prefix='Internet', drop_first=False)\n",
        "print(\"\\nSEM drop_first:\")\n",
        "print(f\"Colunas: {dummy_full.columns.tolist()}\")\n",
        "print(dummy_full.head())\n",
        "\n",
        "# Com drop_first\n",
        "dummy_dropped = pd.get_dummies(df_exemplo['InternetService'], prefix='Internet', drop_first=True)\n",
        "print(\"\\nCOM drop_first:\")\n",
        "print(f\"Colunas: {dummy_dropped.columns.tolist()}\")\n",
        "print(dummy_dropped.head())\n",
        "print(\"\\nCategoria de referência (implícita): DSL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPDfqLl4cpD9"
      },
      "source": [
        "## Verificação Final: Encoding Completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSUKsHLWcpD9"
      },
      "outputs": [],
      "source": [
        "# Verificar se ainda há categóricas\n",
        "print(\"=== VERIFICAÇÃO: ENCODING COMPLETO ===\")\n",
        "\n",
        "categorical_remaining = df.select_dtypes(include='object').columns.tolist()\n",
        "categorical_remaining = [c for c in categorical_remaining if c not in ['customerID', 'Churn']]\n",
        "\n",
        "print(f\"\\nColunas categóricas restantes (exceto IDs): {len(categorical_remaining)}\")\n",
        "\n",
        "if len(categorical_remaining) == 0:\n",
        "    print(\"✓ SUCESSO! Todas as features foram encodadas.\")\n",
        "else:\n",
        "    print(f\"⚠ ATENÇÃO: Ainda há colunas categóricas: {categorical_remaining}\")\n",
        "\n",
        "# Contar features numéricas\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "print(f\"\\nTotal de features numéricas: {len(numeric_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5422jz9CcpD9"
      },
      "source": [
        "## Análise: Correlações com Dados Encodados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqW-SFGscpD-"
      },
      "outputs": [],
      "source": [
        "# Matriz de correlação com features encodadas\n",
        "print(\"=== MATRIZ DE CORRELAÇÃO (SUBSET) ===\")\n",
        "\n",
        "# Selecionar features importantes\n",
        "analysis_features = [\n",
        "    'tenure', 'MonthlyCharges', 'TotalCharges',\n",
        "    'Contract_encoded', 'TotalServices',\n",
        "    'InternetService_Fiber optic', 'InternetService_No',\n",
        "    'PaymentMethod_Electronic check',\n",
        "    'Partner_encoded', 'Dependents_encoded',\n",
        "    'Churn_binary'\n",
        "]\n",
        "\n",
        "# Calcular correlações\n",
        "corr_matrix = df[analysis_features].corr()\n",
        "\n",
        "# Heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5, ax=ax,\n",
        "            cbar_kws={'label': 'Correlação'})\n",
        "ax.set_title('Matriz de Correlação - Features Encodadas', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbW9-_qzcpD-"
      },
      "outputs": [],
      "source": [
        "# Top correlações com Churn\n",
        "correlations = corr_matrix['Churn_binary'].drop('Churn_binary').sort_values(key=abs, ascending=False)\n",
        "\n",
        "print(\"=== TOP 10 CORRELAÇÕES COM CHURN ===\")\n",
        "print(correlations.head(10))\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "correlations.head(10).plot(kind='barh', ax=ax, color='steelblue')\n",
        "ax.set_xlabel('Correlação')\n",
        "ax.set_title('Top 10 Features Correlacionadas com Churn', fontsize=14)\n",
        "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Encoding completo! Próximo: Normalização\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHBlag38cpD-"
      },
      "source": [
        "---\n",
        "\n",
        "# BLOCO 3: Normalização e Padronização\n",
        "\n",
        "**Objetivo:** Colocar variáveis em escalas comparáveis para facilitar análise e visualização.\n",
        "\n",
        "**Técnicas:**\n",
        "1. **Min-Max Scaling** - Escala para [0, 1]\n",
        "2. **Standardization (Z-score)** - Média 0, Desvio Padrão 1\n",
        "3. **Robust Scaling** - Resistente a outliers\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dekRsgKrcpD-"
      },
      "source": [
        "## Problema: Escalas Diferentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYHb2HA7cpD-"
      },
      "outputs": [],
      "source": [
        "# Visualizar problema\n",
        "print(\"=== PROBLEMA: ESCALAS DIFERENTES ===\")\n",
        "\n",
        "comparison_vars = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "for var in comparison_vars:\n",
        "    print(f\"\\n{var}:\")\n",
        "    print(f\"  Min: {df[var].min():.2f}\")\n",
        "    print(f\"  Max: {df[var].max():.2f}\")\n",
        "    print(f\"  Range: {df[var].max() - df[var].min():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TYA81_9cpD-"
      },
      "outputs": [],
      "source": [
        "# Visualizar o problema\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Boxplot mostra escalas incomparáveis\n",
        "df[comparison_vars].boxplot(ax=axes[0])\n",
        "axes[0].set_title('ANTES: Escalas Incomparáveis', fontsize=14)\n",
        "axes[0].set_ylabel('Valores')\n",
        "\n",
        "# Scatter mostra dominância de uma variável\n",
        "axes[1].scatter(df['tenure'], df['TotalCharges'], alpha=0.3)\n",
        "axes[1].set_xlabel('tenure (0-72)')\n",
        "axes[1].set_ylabel('TotalCharges (0-8684)')\n",
        "axes[1].set_title('Escalas Muito Diferentes', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n⚠ Problema: TotalCharges domina visualmente por ter range maior\")\n",
        "print(\"Mas isso NÃO significa que é mais importante!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyx4qcaYcpD-"
      },
      "source": [
        "## Técnica 1: Min-Max Scaling (Normalização)\n",
        "\n",
        "**Fórmula:** $X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n",
        "\n",
        "**Resultado:** Todos os valores entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIEmPZe6cpD-"
      },
      "outputs": [],
      "source": [
        "# Min-Max Scaling\n",
        "print(\"=== MIN-MAX SCALING ===\")\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "# Selecionar colunas numéricas para normalizar\n",
        "numeric_cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "# Aplicar\n",
        "df[[f'{col}_minmax' for col in numeric_cols_to_scale]] = scaler_minmax.fit_transform(\n",
        "    df[numeric_cols_to_scale]\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Min-Max Scaling aplicado\")\n",
        "\n",
        "# Comparar ANTES e DEPOIS\n",
        "print(\"\\n=== ANTES (original) ===\")\n",
        "print(df[numeric_cols_to_scale].describe())\n",
        "\n",
        "print(\"\\n=== DEPOIS (min-max) ===\")\n",
        "minmax_cols = [f'{col}_minmax' for col in numeric_cols_to_scale]\n",
        "print(df[minmax_cols].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUSbyT3OcpD-"
      },
      "outputs": [],
      "source": [
        "# Visualizar transformação\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "for idx, col in enumerate(numeric_cols_to_scale):\n",
        "    # Original\n",
        "    axes[0, idx].hist(df[col], bins=30, color='skyblue', edgecolor='black')\n",
        "    axes[0, idx].set_title(f'Original: {col}')\n",
        "    axes[0, idx].set_xlabel(col)\n",
        "\n",
        "    # Normalizado\n",
        "    axes[1, idx].hist(df[f'{col}_minmax'], bins=30, color='coral', edgecolor='black')\n",
        "    axes[1, idx].set_title(f'Min-Max: {col}')\n",
        "    axes[1, idx].set_xlabel(f'{col} (0-1)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Forma da distribuição preservada, mas escala agora é [0, 1]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cwQM_w9cpD-"
      },
      "source": [
        "## Técnica 2: Standardization (Z-score)\n",
        "\n",
        "**Fórmula:** $X_{scaled} = \\frac{X - \\mu}{\\sigma}$\n",
        "\n",
        "**Resultado:** Média = 0, Desvio Padrão = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ygdAA6GcpD-"
      },
      "outputs": [],
      "source": [
        "# Standardization\n",
        "print(\"=== STANDARDIZATION (Z-SCORE) ===\")\n",
        "\n",
        "scaler_standard = StandardScaler()\n",
        "\n",
        "# Aplicar\n",
        "df[[f'{col}_std' for col in numeric_cols_to_scale]] = scaler_standard.fit_transform(\n",
        "    df[numeric_cols_to_scale]\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Standardization aplicado\")\n",
        "\n",
        "# Verificar resultado\n",
        "print(\"\\n=== DEPOIS (standardized) ===\")\n",
        "std_cols = [f'{col}_std' for col in numeric_cols_to_scale]\n",
        "print(df[std_cols].describe())\n",
        "\n",
        "print(\"\\n✓ Média ≈ 0, Desvio Padrão ≈ 1 (conforme esperado)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOq3Ma9qcpD_"
      },
      "outputs": [],
      "source": [
        "# Interpretação de Z-scores\n",
        "print(\"=== INTERPRETAÇÃO DE Z-SCORES ===\")\n",
        "print(\"\\nExemplo: tenure_std\")\n",
        "\n",
        "tenure_std = df['tenure_std']\n",
        "\n",
        "print(f\"\\nPercentual dentro de ranges:\")\n",
        "print(f\"  Entre -1 e +1 (±1 std): {((tenure_std >= -1) & (tenure_std <= 1)).mean()*100:.1f}%\")\n",
        "print(f\"  Entre -2 e +2 (±2 std): {((tenure_std >= -2) & (tenure_std <= 2)).mean()*100:.1f}%\")\n",
        "print(f\"  Entre -3 e +3 (±3 std): {((tenure_std >= -3) & (tenure_std <= 3)).mean()*100:.1f}%\")\n",
        "\n",
        "outliers = (abs(tenure_std) > 3).sum()\n",
        "print(f\"\\nOutliers (|Z| > 3): {outliers} clientes ({outliers/len(df)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3QMi9slcpD_"
      },
      "outputs": [],
      "source": [
        "# Visualizar Z-scores\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for idx, col in enumerate(numeric_cols_to_scale):\n",
        "    std_col = f'{col}_std'\n",
        "\n",
        "    axes[idx].hist(df[std_col], bins=30, color='lightgreen', edgecolor='black')\n",
        "    axes[idx].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Média (0)')\n",
        "    axes[idx].axvline(x=-1, color='orange', linestyle='--', alpha=0.5, label='±1 std')\n",
        "    axes[idx].axvline(x=1, color='orange', linestyle='--', alpha=0.5)\n",
        "    axes[idx].set_title(f'Z-score: {col}')\n",
        "    axes[idx].set_xlabel('Z-score')\n",
        "    axes[idx].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBzvzmS7cpD_"
      },
      "source": [
        "## Técnica 3: Robust Scaling\n",
        "\n",
        "**Fórmula:** $X_{scaled} = \\frac{X - median}{IQR}$\n",
        "\n",
        "**Vantagem:** Resistente a outliers (usa mediana e IQR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgXv3xnacpD_"
      },
      "outputs": [],
      "source": [
        "# Robust Scaling\n",
        "print(\"=== ROBUST SCALING ===\")\n",
        "\n",
        "scaler_robust = RobustScaler()\n",
        "\n",
        "# Aplicar\n",
        "df[[f'{col}_robust' for col in numeric_cols_to_scale]] = scaler_robust.fit_transform(\n",
        "    df[numeric_cols_to_scale]\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Robust Scaling aplicado\")\n",
        "\n",
        "# Verificar resultado\n",
        "print(\"\\n=== DEPOIS (robust) ===\")\n",
        "robust_cols = [f'{col}_robust' for col in numeric_cols_to_scale]\n",
        "print(df[robust_cols].describe())\n",
        "\n",
        "print(\"\\n✓ Mediana ≈ 0, escala baseada em IQR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvZZ7g9OcpD_"
      },
      "source": [
        "## Comparação: Min-Max vs Standard vs Robust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GHiPphocpD_"
      },
      "outputs": [],
      "source": [
        "# Comparar as três técnicas\n",
        "print(\"=== COMPARAÇÃO DAS TÉCNICAS (tenure) ===\\n\")\n",
        "\n",
        "scaling_methods = {\n",
        "    'Original': 'tenure',\n",
        "    'Min-Max': 'tenure_minmax',\n",
        "    'Standard': 'tenure_std',\n",
        "    'Robust': 'tenure_robust'\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame()\n",
        "for name, col in scaling_methods.items():\n",
        "    comparison_df[name] = [\n",
        "        df[col].min(),\n",
        "        df[col].quantile(0.25),\n",
        "        df[col].median(),\n",
        "        df[col].mean(),\n",
        "        df[col].quantile(0.75),\n",
        "        df[col].max(),\n",
        "        df[col].std()\n",
        "    ]\n",
        "\n",
        "comparison_df.index = ['Min', 'Q1', 'Median', 'Mean', 'Q3', 'Max', 'Std']\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98PU8GVVcpD_"
      },
      "outputs": [],
      "source": [
        "# Visualizar comparação lado a lado\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "for idx, (name, col) in enumerate(scaling_methods.items()):\n",
        "    axes[idx].hist(df[col], bins=30, color=['skyblue', 'coral', 'lightgreen', 'orchid'][idx],\n",
        "                   edgecolor='black')\n",
        "    axes[idx].set_title(name, fontsize=12)\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].axvline(x=df[col].mean(), color='red', linestyle='--', alpha=0.7, label='Mean')\n",
        "    axes[idx].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Mesma distribuição, escalas diferentes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQgfk-TcpEA"
      },
      "source": [
        "## Comparação Visual: ANTES vs DEPOIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxkErJKncpEA"
      },
      "outputs": [],
      "source": [
        "# Boxplot comparativo\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ANTES: escalas incomparáveis\n",
        "df[numeric_cols_to_scale].boxplot(ax=axes[0])\n",
        "axes[0].set_title('ANTES: Escalas Incomparáveis', fontsize=14)\n",
        "axes[0].set_ylabel('Valores Originais')\n",
        "\n",
        "# DEPOIS: escalas comparáveis (usando Standard)\n",
        "df[std_cols].boxplot(ax=axes[1])\n",
        "axes[1].set_title('DEPOIS: Escalas Comparáveis (Z-score)', fontsize=14)\n",
        "axes[1].set_ylabel('Z-score')\n",
        "axes[1].set_xticklabels(['tenure', 'MonthlyCharges', 'TotalCharges'])\n",
        "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Agora podemos comparar variáveis diretamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU_X7_dgcpEA"
      },
      "source": [
        "## Boa Prática: Separar Dados para Validação\n",
        "\n",
        "**Importante:** Em cenários reais, devemos treinar o scaler apenas nos dados de treino e aplicar aos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJCZBMx_cpEA"
      },
      "outputs": [],
      "source": [
        "# Demonstração de fit vs transform\n",
        "print(\"=== BOA PRÁTICA: FIT vs TRANSFORM ===\")\n",
        "\n",
        "# Separar dados (80% treino, 20% teste)\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTreino: {len(df_train)} registros\")\n",
        "print(f\"Teste: {len(df_test)} registros\")\n",
        "\n",
        "# Criar scaler\n",
        "scaler_demo = StandardScaler()\n",
        "\n",
        "# FIT apenas no treino\n",
        "scaler_demo.fit(df_train[numeric_cols_to_scale])\n",
        "\n",
        "print(\"\\n=== PARÂMETROS APRENDIDOS (do treino) ===\")\n",
        "print(f\"Médias: {scaler_demo.mean_}\")\n",
        "print(f\"Desvios: {scaler_demo.scale_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExgO6TWgcpEA"
      },
      "outputs": [],
      "source": [
        "# TRANSFORM em ambos (usando mesmos parâmetros)\n",
        "train_scaled = scaler_demo.transform(df_train[numeric_cols_to_scale])\n",
        "test_scaled = scaler_demo.transform(df_test[numeric_cols_to_scale])\n",
        "\n",
        "# Verificar\n",
        "print(\"=== VERIFICAÇÃO ===\")\n",
        "print(\"\\nConjunto TREINO:\")\n",
        "print(f\"  Média tenure: {train_scaled[:, 0].mean():.3f} (≈ 0)\")\n",
        "print(f\"  Std tenure: {train_scaled[:, 0].std():.3f} (≈ 1)\")\n",
        "\n",
        "print(\"\\nConjunto TESTE:\")\n",
        "print(f\"  Média tenure: {test_scaled[:, 0].mean():.3f} (pode ≠ 0)\")\n",
        "print(f\"  Std tenure: {test_scaled[:, 0].std():.3f} (pode ≠ 1)\")\n",
        "\n",
        "print(\"\\n✓ Teste usa parâmetros do treino (correto!)\")\n",
        "print(\"Isso simula como seria com dados futuros em produção.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TUKWYL7cpEA"
      },
      "source": [
        "## Resumo do Bloco 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfWihnHNcpEA"
      },
      "outputs": [],
      "source": [
        "# Resumo das técnicas\n",
        "print(\"=== RESUMO: NORMALIZAÇÃO E PADRONIZAÇÃO ===\")\n",
        "print(\"\\n1. MIN-MAX SCALING\")\n",
        "print(\"   - Range: [0, 1]\")\n",
        "print(\"   - Use quando: quer valores entre 0 e 1\")\n",
        "print(\"   - Sensível a: outliers\")\n",
        "\n",
        "print(\"\\n2. STANDARDIZATION (Z-SCORE)\")\n",
        "print(\"   - Média: 0, Std: 1\")\n",
        "print(\"   - Use quando: quer centralizar em zero\")\n",
        "print(\"   - Interpretação: desvios padrão\")\n",
        "\n",
        "print(\"\\n3. ROBUST SCALING\")\n",
        "print(\"   - Baseado em: mediana e IQR\")\n",
        "print(\"   - Use quando: muitos outliers\")\n",
        "print(\"   - Resistente a: valores extremos\")\n",
        "\n",
        "print(\"\\n✓ Todas preservam a forma da distribuição\")\n",
        "print(\"✓ Apenas mudam a escala\")\n",
        "print(\"\\n✓ Pronto para análises avançadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfivOgCMcpEA"
      },
      "source": [
        "---\n",
        "\n",
        "**Checkpoint:** Salvar dataset com todas as transformações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhXQ3b_ecpEA"
      },
      "outputs": [],
      "source": [
        "# Salvar dataset transformado\n",
        "df.to_csv('telco_churn_transformed.csv', index=False)\n",
        "print(\"✓ Dataset salvo: telco_churn_transformed.csv\")\n",
        "print(f\"Shape final: {df.shape}\")\n",
        "print(f\"\\n✓ Transformações completas:\")\n",
        "print(\"  - Feature Engineering\")\n",
        "print(\"  - Encoding\")\n",
        "print(\"  - Normalização\")\n",
        "print(\"\\nPróximo: Pipeline completo e análise final!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R9GlhgNcpEB"
      },
      "source": [
        "# Aula 10 - PARTE 3: Pipeline Completo e Análise Final\n",
        "\n",
        "**Integração de todas as transformações**\n",
        "\n",
        "Nesta parte:\n",
        "- **Bloco 4:** Pipeline end-to-end\n",
        "- Análise exploratória avançada com dados transformados\n",
        "- Conclusões e próximos passos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6E9T38qcpEB"
      },
      "source": [
        "## Setup (caso esteja começando daqui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi6tZQqOcpEB"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Configurações\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Setup completo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MkD95-ccpEB"
      },
      "outputs": [],
      "source": [
        "# Carregar dados originais (vamos aplicar pipeline do zero)\n",
        "url = 'https://raw.githubusercontent.com/marvin-rubia/Churn-Analysis-Prediction/main/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
        "df_original = pd.read_csv(url)\n",
        "\n",
        "\n",
        "# Tratamento básico\n",
        "df_original['TotalCharges'] = pd.to_numeric(df_original['TotalCharges'], errors='coerce')\n",
        "df_original['TotalCharges'].fillna(df_original['MonthlyCharges'], inplace=True)\n",
        "\n",
        "print(f\"Dataset original: {df_original.shape}\")\n",
        "print(\"✓ Pronto para aplicar pipeline completo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwx8GEKtcpEC"
      },
      "source": [
        "---\n",
        "\n",
        "# BLOCO 4: Pipeline Completo\n",
        "\n",
        "**Objetivo:** Criar função única que aplica todas as transformações de uma vez.\n",
        "\n",
        "**Benefícios:**\n",
        "- Reproduzível\n",
        "- Organizado\n",
        "- Fácil de aplicar em dados novos\n",
        "- Evita erros de esquecimento de etapas\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLcSpd4RcpEC"
      },
      "source": [
        "## Criar Função Pipeline Completa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88vBe1rRcpEC"
      },
      "outputs": [],
      "source": [
        "def transform_telco_churn(df, fit_scaler=True, scaler=None):\n",
        "    \"\"\"\n",
        "    Pipeline completo de transformação para Telco Churn Dataset\n",
        "\n",
        "    Aplica:\n",
        "    1. Feature Engineering\n",
        "    2. Encoding de categóricas\n",
        "    3. Normalização (Standardization)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Dataset bruto\n",
        "    fit_scaler : bool\n",
        "        Se True, fit novo scaler. Se False, usa scaler fornecido\n",
        "    scaler : sklearn scaler, optional\n",
        "        Scaler pré-treinado (para aplicar em dados novos)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    df_transformed : DataFrame\n",
        "        Dataset transformado\n",
        "    scaler : StandardScaler\n",
        "        Scaler treinado (para usar em dados futuros)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=== INICIANDO PIPELINE DE TRANSFORMAÇÃO ===\")\n",
        "    df_transformed = df.copy()\n",
        "\n",
        "    # ===== 1. FEATURE ENGINEERING =====\n",
        "    print(\"\\n1. Feature Engineering...\")\n",
        "\n",
        "    # Operações aritméticas\n",
        "    df_transformed['AvgMonthlySpend'] = df_transformed['TotalCharges'] / df_transformed['tenure']\n",
        "    df_transformed['AvgMonthlySpend'] = df_transformed['AvgMonthlySpend'].replace([np.inf, -np.inf], np.nan)\n",
        "    df_transformed.loc[df_transformed['tenure'] == 0, 'AvgMonthlySpend'] = \\\n",
        "        df_transformed.loc[df_transformed['tenure'] == 0, 'MonthlyCharges']\n",
        "\n",
        "    # Agregações\n",
        "    service_cols = ['PhoneService', 'MultipleLines', 'InternetService',\n",
        "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                   'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
        "\n",
        "    df_transformed['TotalServices'] = 0\n",
        "    for col in service_cols:\n",
        "        df_transformed['TotalServices'] += (\n",
        "            ~df_transformed[col].isin(['No', 'No internet service', 'No phone service'])\n",
        "        ).astype(int)\n",
        "\n",
        "    # Flags\n",
        "    df_transformed['IsPremium'] = (\n",
        "        (df_transformed['TotalServices'] >= 6) &\n",
        "        (df_transformed['Contract'].isin(['One year', 'Two year']))\n",
        "    ).astype(int)\n",
        "\n",
        "    df_transformed['HighRiskProfile'] = (\n",
        "        (df_transformed['Contract'] == 'Month-to-month') &\n",
        "        (df_transformed['tenure'] < 12) &\n",
        "        (df_transformed['TotalServices'] <= 2) &\n",
        "        (df_transformed['PaymentMethod'] == 'Electronic check')\n",
        "    ).astype(int)\n",
        "\n",
        "    print(\"   ✓ Features criadas: AvgMonthlySpend, TotalServices, IsPremium, HighRiskProfile\")\n",
        "\n",
        "    # ===== 2. ENCODING =====\n",
        "    print(\"\\n2. Encoding...\")\n",
        "\n",
        "    # Ordinais (Label)\n",
        "    contract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
        "    df_transformed['Contract_encoded'] = df_transformed['Contract'].map(contract_map)\n",
        "\n",
        "    # Binárias\n",
        "    binary_vars = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "    for col in binary_vars:\n",
        "        if col == 'gender':\n",
        "            df_transformed[f'{col}_encoded'] = (df_transformed[col] == 'Male').astype(int)\n",
        "        else:\n",
        "            df_transformed[f'{col}_encoded'] = (df_transformed[col] == 'Yes').astype(int)\n",
        "\n",
        "    df_transformed['SeniorCitizen_encoded'] = df_transformed['SeniorCitizen']\n",
        "\n",
        "    # Serviços com \"No service\"\n",
        "    service_with_no = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
        "                       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
        "    for col in service_with_no:\n",
        "        df_transformed[f'{col}_encoded'] = (df_transformed[col] == 'Yes').astype(int)\n",
        "\n",
        "    # Nominais (One-Hot)\n",
        "    nominal_vars = ['PaymentMethod', 'InternetService']\n",
        "    df_transformed = pd.get_dummies(df_transformed,\n",
        "                                    columns=nominal_vars,\n",
        "                                    prefix=nominal_vars,\n",
        "                                    drop_first=True,\n",
        "                                    dtype=int)\n",
        "\n",
        "    print(\"   ✓ Encoding completo: Label, Binary, One-Hot\")\n",
        "\n",
        "    # ===== 3. NORMALIZAÇÃO =====\n",
        "    print(\"\\n3. Normalização (Standardization)...\")\n",
        "\n",
        "    # Colunas para normalizar\n",
        "    numeric_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges',\n",
        "                        'AvgMonthlySpend', 'TotalServices']\n",
        "\n",
        "    if fit_scaler:\n",
        "        # Criar e treinar novo scaler\n",
        "        scaler = StandardScaler()\n",
        "        df_transformed[numeric_to_scale] = scaler.fit_transform(df_transformed[numeric_to_scale])\n",
        "        print(\"   ✓ Scaler treinado e aplicado\")\n",
        "    else:\n",
        "        # Usar scaler existente\n",
        "        if scaler is None:\n",
        "            raise ValueError(\"Forneça scaler quando fit_scaler=False\")\n",
        "        df_transformed[numeric_to_scale] = scaler.transform(df_transformed[numeric_to_scale])\n",
        "        print(\"   ✓ Scaler existente aplicado\")\n",
        "\n",
        "    # Target binário\n",
        "    df_transformed['Churn_binary'] = (df_transformed['Churn'] == 'Yes').astype(int)\n",
        "\n",
        "    print(\"\\n=== PIPELINE COMPLETO! ===\")\n",
        "    print(f\"Shape: {df_original.shape} → {df_transformed.shape}\")\n",
        "\n",
        "    return df_transformed, scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FM0I4yBcpEC"
      },
      "source": [
        "## Aplicar Pipeline ao Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdaHdz2TcpEC"
      },
      "outputs": [],
      "source": [
        "# Aplicar pipeline\n",
        "df_final, trained_scaler = transform_telco_churn(df_original, fit_scaler=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRANSFORMAÇÃO COMPLETA!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5S9umsrcpED"
      },
      "source": [
        "## Validar Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Doq3DRmxcpED"
      },
      "outputs": [],
      "source": [
        "# Checklist de validação\n",
        "print(\"=== CHECKLIST DE VALIDAÇÃO ===\")\n",
        "\n",
        "# 1. Missing values\n",
        "missing = df_final.isnull().sum().sum()\n",
        "print(f\"\\n1. Missing values: {missing}\")\n",
        "if missing == 0:\n",
        "    print(\"   ✓ Nenhum missing value\")\n",
        "else:\n",
        "    print(f\"   ⚠ {missing} missing values encontrados\")\n",
        "\n",
        "# 2. Variáveis categóricas restantes\n",
        "cat_cols = df_final.select_dtypes('object').columns.tolist()\n",
        "cat_cols = [c for c in cat_cols if c not in ['customerID', 'Churn']]\n",
        "print(f\"\\n2. Categóricas restantes (exceto IDs): {len(cat_cols)}\")\n",
        "if len(cat_cols) == 0:\n",
        "    print(\"   ✓ Todas encodadas\")\n",
        "else:\n",
        "    print(f\"   ⚠ Ainda há categóricas: {cat_cols}\")\n",
        "\n",
        "# 3. Features numéricas\n",
        "numeric_features = df_final.select_dtypes(include=['int64', 'float64']).columns\n",
        "print(f\"\\n3. Features numéricas: {len(numeric_features)}\")\n",
        "print(f\"   ✓ {len(numeric_features)} features prontas para análise\")\n",
        "\n",
        "# 4. Verificar normalização\n",
        "print(\"\\n4. Normalização (tenure, MonthlyCharges, TotalCharges):\")\n",
        "for col in ['tenure', 'MonthlyCharges', 'TotalCharges']:\n",
        "    mean = df_final[col].mean()\n",
        "    std = df_final[col].std()\n",
        "    print(f\"   {col}: média={mean:.3f}, std={std:.3f}\")\n",
        "print(\"   ✓ Média ≈ 0, Std ≈ 1 (normalizado)\")\n",
        "\n",
        "# 5. Target\n",
        "print(f\"\\n5. Target (Churn_binary):\")\n",
        "print(f\"   Distribuição: {df_final['Churn_binary'].value_counts().to_dict()}\")\n",
        "print(f\"   Taxa de Churn: {df_final['Churn_binary'].mean()*100:.1f}%\")\n",
        "print(\"   ✓ Target criado corretamente\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ TODAS AS VALIDAÇÕES PASSARAM!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Lc1rj6cpED"
      },
      "source": [
        "---\n",
        "\n",
        "## Análise Exploratória Avançada\n",
        "\n",
        "Agora que os dados estão completamente transformados, podemos fazer análises que não eram possíveis antes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i3rtru7cpED"
      },
      "source": [
        "### 1. Matriz de Correlação Completa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnoPM9iZcpED"
      },
      "outputs": [],
      "source": [
        "# Selecionar features importantes para análise\n",
        "analysis_features = [\n",
        "    # Numéricas originais (normalizadas)\n",
        "    'tenure', 'MonthlyCharges', 'TotalCharges',\n",
        "    # Features criadas\n",
        "    'AvgMonthlySpend', 'TotalServices',\n",
        "    # Encodadas\n",
        "    'Contract_encoded', 'IsPremium', 'HighRiskProfile',\n",
        "    'SeniorCitizen_encoded', 'Partner_encoded', 'Dependents_encoded',\n",
        "    # One-Hot (exemplos)\n",
        "    'InternetService_Fiber optic', 'InternetService_No',\n",
        "    'PaymentMethod_Electronic check',\n",
        "    # Target\n",
        "    'Churn_binary'\n",
        "]\n",
        "\n",
        "# Calcular matriz de correlação\n",
        "corr_matrix = df_final[analysis_features].corr()\n",
        "\n",
        "# Heatmap\n",
        "fig, ax = plt.subplots(figsize=(14, 12))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5,\n",
        "            cbar_kws={'label': 'Correlação'}, ax=ax)\n",
        "ax.set_title('Matriz de Correlação - Dataset Transformado', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Matriz de correlação com todas as features transformadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGxsjuXncpED"
      },
      "source": [
        "### 2. Análise de Importância das Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0nHja7JcpED"
      },
      "outputs": [],
      "source": [
        "# Top correlações com Churn\n",
        "print(\"=== TOP 20 FEATURES MAIS CORRELACIONADAS COM CHURN ===\")\n",
        "\n",
        "correlations_with_churn = corr_matrix['Churn_binary'].drop('Churn_binary')\n",
        "top_20 = correlations_with_churn.abs().sort_values(ascending=False).head(20)\n",
        "\n",
        "print(\"\\nFeature | Correlação\")\n",
        "print(\"-\" * 50)\n",
        "for feat, corr in top_20.items():\n",
        "    actual_corr = correlations_with_churn[feat]\n",
        "    direction = \"↑ aumenta\" if actual_corr > 0 else \"↓ reduz\"\n",
        "    print(f\"{feat:35} | {actual_corr:+.3f} ({direction} churn)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjP0x8oNcpED"
      },
      "outputs": [],
      "source": [
        "# Visualizar top correlações\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Separar positivas e negativas\n",
        "top_corr = correlations_with_churn.abs().sort_values(ascending=False).head(15)\n",
        "values = [correlations_with_churn[feat] for feat in top_corr.index]\n",
        "colors = ['salmon' if v > 0 else 'skyblue' for v in values]\n",
        "\n",
        "ax.barh(range(len(top_corr)), values, color=colors)\n",
        "ax.set_yticks(range(len(top_corr)))\n",
        "ax.set_yticklabels(top_corr.index)\n",
        "ax.set_xlabel('Correlação com Churn', fontsize=12)\n",
        "ax.set_title('Top 15 Features por Correlação com Churn', fontsize=14)\n",
        "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Legenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='salmon', label='Positiva (↑ churn)'),\n",
        "    Patch(facecolor='skyblue', label='Negativa (↓ churn)')\n",
        "]\n",
        "ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5p6zc9ocpED"
      },
      "source": [
        "### 3. Insights de Negócio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rKls0k4cpED"
      },
      "outputs": [],
      "source": [
        "# Extrair insights principais\n",
        "print(\"=== INSIGHTS DE NEGÓCIO ===\")\n",
        "print(\"\\nFatores que AUMENTAM churn (correlação positiva):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "positive_corr = correlations_with_churn[correlations_with_churn > 0].sort_values(ascending=False)\n",
        "for feat, corr in positive_corr.head(5).items():\n",
        "    print(f\"  • {feat}: {corr:.3f}\")\n",
        "\n",
        "print(\"\\nFatores que REDUZEM churn (correlação negativa):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "negative_corr = correlations_with_churn[correlations_with_churn < 0].sort_values()\n",
        "for feat, corr in negative_corr.head(5).items():\n",
        "    print(f\"  • {feat}: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvdzjF_0cpEE"
      },
      "outputs": [],
      "source": [
        "# Recomendações baseadas nos dados\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RECOMENDAÇÕES PARA REDUZIR CHURN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. FOCO EM CONTRATOS LONGOS\")\n",
        "print(\"   • Contract_encoded tem correlação negativa forte (-0.40+)\")\n",
        "print(\"   • Ação: Incentivar migração de month-to-month para anual\")\n",
        "print(\"   • Estratégia: Descontos para contratos de 1-2 anos\")\n",
        "\n",
        "print(\"\\n2. AUMENTAR ENGAJAMENTO (SERVIÇOS)\")\n",
        "print(\"   • TotalServices correlaciona negativamente com churn\")\n",
        "print(\"   • Ação: Cross-sell de serviços adicionais\")\n",
        "print(\"   • Estratégia: Bundles atrativos de múltiplos serviços\")\n",
        "\n",
        "print(\"\\n3. ATENÇÃO A PERFIS DE ALTO RISCO\")\n",
        "print(\"   • HighRiskProfile identifica clientes vulneráveis\")\n",
        "print(\"   • Ação: Programa de retenção proativa\")\n",
        "print(\"   • Estratégia: Contato preventivo antes do churn\")\n",
        "\n",
        "print(\"\\n4. REVISAR FIBRA ÓPTICA\")\n",
        "print(\"   • InternetService_Fiber optic aumenta churn\")\n",
        "print(\"   • Possível causa: Preço vs expectativa\")\n",
        "print(\"   • Ação: Investigar satisfação e ajustar preço/qualidade\")\n",
        "\n",
        "print(\"\\n5. MÉTODO DE PAGAMENTO\")\n",
        "print(\"   • Electronic check associado a mais churn\")\n",
        "print(\"   • Ação: Incentivar métodos mais estáveis (débito automático)\")\n",
        "print(\"   • Estratégia: Descontos para débito automático\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ81YefBcpEE"
      },
      "source": [
        "### 4. Comparação: Antes vs Depois das Transformações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTZc1FzdcpEE"
      },
      "outputs": [],
      "source": [
        "# Visualização lado a lado\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. ANTES: Variáveis em escalas diferentes\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "df_original[['tenure', 'MonthlyCharges', 'TotalCharges']].boxplot(ax=ax1)\n",
        "ax1.set_title('ANTES: Escalas Incomparáveis', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Valores Originais')\n",
        "\n",
        "# 2. DEPOIS: Variáveis normalizadas\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "df_final[['tenure', 'MonthlyCharges', 'TotalCharges']].boxplot(ax=ax2)\n",
        "ax2.set_title('DEPOIS: Escalas Comparáveis', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Z-score')\n",
        "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# 3. ANTES: Poucas features numéricas\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "original_numeric = df_original.select_dtypes(include=['int64', 'float64']).columns\n",
        "ax3.text(0.5, 0.5, f'Features Numéricas\\nOriginais: {len(original_numeric)}\\n\\n' +\n",
        "         '\\n'.join(original_numeric[:10].tolist()),\n",
        "         ha='center', va='center', fontsize=11,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
        "ax3.set_xlim(0, 1)\n",
        "ax3.set_ylim(0, 1)\n",
        "ax3.axis('off')\n",
        "ax3.set_title('ANTES: Poucas Features', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 4. DEPOIS: Muitas features numéricas\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "final_numeric = df_final.select_dtypes(include=['int64', 'float64']).columns\n",
        "ax4.text(0.5, 0.5, f'Features Numéricas\\nFinais: {len(final_numeric)}\\n\\n' +\n",
        "         f'+ {len(final_numeric) - len(original_numeric)} features criadas!',\n",
        "         ha='center', va='center', fontsize=11,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
        "ax4.set_xlim(0, 1)\n",
        "ax4.set_ylim(0, 1)\n",
        "ax4.axis('off')\n",
        "ax4.set_title('DEPOIS: Muitas Features', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 5. ANTES: Apenas 3 correlações possíveis\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "original_corr = df_original[['tenure', 'MonthlyCharges', 'TotalCharges']].corr()\n",
        "sns.heatmap(original_corr, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, ax=ax5, cbar=False)\n",
        "ax5.set_title('ANTES: Correlações Limitadas', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 6. DEPOIS: Análise rica de correlações\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "subset_features = ['tenure', 'MonthlyCharges', 'Contract_encoded',\n",
        "                   'TotalServices', 'IsPremium', 'Churn_binary']\n",
        "final_corr = df_final[subset_features].corr()\n",
        "sns.heatmap(final_corr, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, ax=ax6, cbar=False)\n",
        "ax6.set_title('DEPOIS: Análise Rica', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.suptitle('IMPACTO DAS TRANSFORMAÇÕES', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Transformações permitiram análises que eram impossíveis antes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRAU6RpcpEE"
      },
      "source": [
        "### 5. Perfis de Clientes Transformados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFvus-KbcpEE"
      },
      "outputs": [],
      "source": [
        "# Analisar perfis criados\n",
        "print(\"=== ANÁLISE DE PERFIS ===\")\n",
        "\n",
        "profiles = ['IsPremium', 'HighRiskProfile']\n",
        "\n",
        "for profile in profiles:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{profile}\")\n",
        "    print('='*60)\n",
        "\n",
        "    # Quantidade\n",
        "    count = df_final[profile].sum()\n",
        "    pct = df_final[profile].mean() * 100\n",
        "    print(f\"\\nQuantidade: {count} clientes ({pct:.1f}% da base)\")\n",
        "\n",
        "    # Churn rate\n",
        "    churn_rate_with = df_final[df_final[profile] == 1]['Churn_binary'].mean()\n",
        "    churn_rate_without = df_final[df_final[profile] == 0]['Churn_binary'].mean()\n",
        "    baseline = df_final['Churn_binary'].mean()\n",
        "\n",
        "    print(f\"\\nTaxa de Churn:\")\n",
        "    print(f\"  Com {profile}=1: {churn_rate_with*100:.1f}%\")\n",
        "    print(f\"  Com {profile}=0: {churn_rate_without*100:.1f}%\")\n",
        "    print(f\"  Baseline (geral): {baseline*100:.1f}%\")\n",
        "    print(f\"  Diferença: {(churn_rate_with - baseline)*100:+.1f} pontos percentuais\")\n",
        "\n",
        "    # Características médias\n",
        "    print(f\"\\nCaracterísticas médias (com {profile}=1):\")\n",
        "    subset = df_final[df_final[profile] == 1]\n",
        "    print(f\"  Tenure (meses): {subset['tenure'].mean():.2f} (original: {df_original[df_original.index.isin(subset.index)]['tenure'].mean():.0f})\")\n",
        "    print(f\"  MonthlyCharges: R$ {df_original[df_original.index.isin(subset.index)]['MonthlyCharges'].mean():.2f}\")\n",
        "    print(f\"  TotalServices: {df_original[df_original.index.isin(subset.index)]['TotalServices'].mean():.1f}\" if 'TotalServices' in df_original.columns else \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3H2VYRlcpEE"
      },
      "source": [
        "---\n",
        "\n",
        "## Conclusão e Próximos Passos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkG2uePxcpEE"
      },
      "source": [
        "### O que Aprendemos Hoje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsLzdHpicpEE"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"RESUMO DA AULA 10: PRÉ-PROCESSAMENTO DE DADOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. FEATURE ENGINEERING\")\n",
        "print(\"   ✓ Criamos variáveis derivadas úteis\")\n",
        "print(\"   ✓ 12 técnicas diferentes aplicadas\")\n",
        "print(\"   ✓ Validação através de correlações e visualizações\")\n",
        "print(f\"   → Resultado: {len([c for c in df_final.columns if c not in df_original.columns])} novas features\")\n",
        "\n",
        "print(\"\\n2. ENCODING\")\n",
        "print(\"   ✓ Convertemos todas as categóricas em numéricas\")\n",
        "print(\"   ✓ Label (ordinais), One-Hot (nominais), Binary (sim/não)\")\n",
        "print(\"   ✓ Estratégia apropriada para cada tipo\")\n",
        "original_categorical = len(df_original.select_dtypes('object').columns) - 2  # -2 for ID and target\n",
        "print(f\"   → Resultado: {original_categorical} variáveis categóricas encodadas\")\n",
        "\n",
        "print(\"\\n3. NORMALIZAÇÃO\")\n",
        "print(\"   ✓ Colocamos variáveis em escalas comparáveis\")\n",
        "print(\"   ✓ Min-Max, Standardization, Robust Scaling\")\n",
        "print(\"   ✓ Escolha da técnica apropriada\")\n",
        "print(\"   → Resultado: Todas as variáveis comparáveis (Z-score)\")\n",
        "\n",
        "print(\"\\n4. PIPELINE COMPLETO\")\n",
        "print(\"   ✓ Função reproduzível end-to-end\")\n",
        "print(\"   ✓ Aplicável a dados novos\")\n",
        "print(\"   ✓ Organizado e documentado\")\n",
        "print(\"   → Resultado: Pipeline pronto para produção\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"IMPACTO\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Shape: {df_original.shape} → {df_final.shape}\")\n",
        "print(f\"Features numéricas: {len(df_original.select_dtypes('number').columns)} → {len(df_final.select_dtypes('number').columns)}\")\n",
        "print(f\"Análises possíveis: BÁSICAS → AVANÇADAS\")\n",
        "print(\"\\n✓ DADOS PRONTOS PARA ANÁLISES SOFISTICADAS!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZWoemYcpEF"
      },
      "source": [
        "### Conexão com Machine Learning (Preview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gJzW89YcpEF"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PREVIEW: CONEXÃO COM MACHINE LEARNING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nO QUE FIZEMOS HOJE:\")\n",
        "print(\"  • Feature Engineering → criar variáveis úteis\")\n",
        "print(\"  • Encoding → converter para números\")\n",
        "print(\"  • Normalização → escalas comparáveis\")\n",
        "print(\"  • OBJETIVO: Análise exploratória avançada\")\n",
        "\n",
        "print(\"\\nEM MACHINE LEARNING (CURSOS FUTUROS):\")\n",
        "print(\"  • Usaremos EXATAMENTE o mesmo pipeline\")\n",
        "print(\"  • Mas ao invés de análise manual...\")\n",
        "print(\"  • Treinaremos algoritmos para aprender padrões automaticamente\")\n",
        "print(\"  • Ex: Algoritmo aprende que 'Contract_encoded=2 + TotalServices≥6 → baixo churn'\")\n",
        "print(\"  • Depois aplica em clientes novos para prever risco\")\n",
        "\n",
        "print(\"\\n✓ Você já domina a FUNDAÇÃO essencial para ML!\")\n",
        "print(\"✓ Mesmas transformações, objetivos diferentes\")\n",
        "print(\"✓ Quando chegar em ML, já saberá preparar dados corretamente\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_TeKJYccpEF"
      },
      "source": [
        "### Salvar Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yyvZinOcpEF"
      },
      "outputs": [],
      "source": [
        "# Salvar dataset final\n",
        "df_final.to_csv('telco_churn_final_transformed.csv', index=False)\n",
        "print(\"✓ Dataset final salvo: telco_churn_final_transformed.csv\")\n",
        "\n",
        "# Salvar scaler (para usar em dados futuros)\n",
        "import joblib\n",
        "joblib.dump(trained_scaler, 'scaler_telco_churn.pkl')\n",
        "print(\"✓ Scaler salvo: scaler_telco_churn.pkl\")\n",
        "\n",
        "print(\"\\n✓ Todos os artefatos salvos!\")\n",
        "print(\"\\nArquivos gerados:\")\n",
        "print(\"  • telco_churn_final_transformed.csv - Dataset transformado\")\n",
        "print(\"  • scaler_telco_churn.pkl - Scaler treinado\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}