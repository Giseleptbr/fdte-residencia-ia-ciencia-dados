{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Aula 06 - Pr√°tica Guiada\n",
        "\n",
        "**Curso:** Programa√ß√£o para Ci√™ncia de Dados  \n",
        "**Aluno:** [Seu Nome Aqui]  \n",
        "**Data:** [Data Atual]\n",
        "\n",
        "---\n",
        "\n",
        "## Conte√∫do\n",
        "\n",
        "### Bloco 1 - Transforma√ß√µes\n",
        "- Named Aggregations (sintaxe moderna)\n",
        "- Binning com qcut (faixas balanceadas)\n",
        "\n",
        "### Bloco 2 - GroupBy\n",
        "- Window Functions (pct_change, diff, shift)\n",
        "- Ranking dentro de grupos\n",
        "\n",
        "### Bloco 3 - Combina√ß√£o de DataFrames\n",
        "- Merge com valida√ß√£o (prevenir erros)\n",
        "- Diferentes tipos de JOIN\n",
        "\n",
        "### Bloco 4 - Reshape e Pivot\n",
        "- Pivot tables avan√ßadas\n",
        "- Transform para normaliza√ß√£o por grupo\n",
        "- Method chaining (pipeline completo)\n",
        "---\n",
        "\n",
        "## Objetivos de Aprendizagem\n",
        "\n",
        "Ao final desta pr√°tica, voc√™ saber√°:\n",
        "1. Usar named aggregations para c√≥digo mais leg√≠vel\n",
        "2. Criar faixas balanceadas com qcut\n",
        "3. Calcular varia√ß√µes percentuais entre per√≠odos\n",
        "4. Criar rankings dentro de grupos espec√≠ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# === CONFIGURA√á√ÉO INICIAL ===\n",
        "\n",
        "!pip install --upgrade pip --quiet\n",
        "!pip cache purge\n",
        "!pip install otter-grader --no-cache-dir -q\n",
        "!mkdir -p tests\n",
        "\n",
        "print(\"‚úì Otter Grader instalado!\")\n",
        "print(\"‚úì Diret√≥rio de testes criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p1.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p1\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'categoria': ['A', 'B', 'A'], 'valor': [10, 20, 30]})\n",
        ">>> resultado = agrupar_com_named_agg(df)\n",
        ">>> isinstance(resultado, pd.DataFrame) and 'valor_total' in resultado.columns\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p2"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p2.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p2\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'valor': [10, 20, 30, 40, 50, 60, 70, 80]})\n",
        ">>> resultado = criar_faixas_balanceadas(df)\n",
        ">>> 'faixa' in resultado.columns and resultado['faixa'].nunique() == 4\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p3"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p3.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p3\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'mes': [1, 2, 3], 'vendas': [100, 120, 110]})\n",
        ">>> resultado = calcular_variacao_percentual(df)\n",
        ">>> 'variacao_pct' in resultado.columns\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p4"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p4.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p4\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'categoria': ['A', 'A', 'B', 'B'], 'valor': [10, 20, 15, 25]})\n",
        ">>> resultado = criar_ranking_por_grupo(df)\n",
        ">>> 'rank' in resultado.columns\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41dsjxZimyM3"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p5.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p5\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df1 = pd.DataFrame({'id': [1, 2, 3], 'nome': ['A', 'B', 'C']})\n",
        ">>> df2 = pd.DataFrame({'id': [1, 2, 3], 'valor': [10, 20, 30]})\n",
        ">>> resultado = fazer_merge_validado(df1, df2)\n",
        ">>> len(resultado) == 3 and len(resultado.columns) == 3\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p6"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p6.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p6\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'produto': ['A', 'B'], 'mes': ['Jan', 'Jan'], 'vendas': [10, 20]})\n",
        ">>> resultado = criar_pivot_avancado(df)\n",
        ">>> isinstance(resultado, pd.DataFrame)\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p7"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p7.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p7\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({'grupo': ['A', 'A', 'B', 'B'], 'valor': [10, 20, 30, 40]})\n",
        ">>> resultado = normalizar_por_grupo(df)\n",
        ">>> 'valor_normalizado' in resultado.columns\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tests_p8"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p8.py\n",
        "OK_FORMAT = True\n",
        "test = {\n",
        "    \"name\": \"p8\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [{\n",
        "        \"cases\": [{\n",
        "            \"code\": r\"\"\"\n",
        ">>> import pandas as pd\n",
        ">>> df = pd.DataFrame({\n",
        "...     'categoria': ['A', 'B', 'A', 'C', 'B'],\n",
        "...     'preco': [100, 200, 150, 80, 180],\n",
        "...     'custo': [60, 120, 90, 50, 110],\n",
        "...     'quantidade': [2, 1, 3, 4, 2]\n",
        "... })\n",
        ">>> resultado = pipeline_completo(df)\n",
        ">>> isinstance(resultado, pd.DataFrame) and len(resultado) > 0\n",
        "True\n",
        ">>> 'receita_total' in resultado.columns and 'margem_total' in resultado.columns\n",
        "True\n",
        ">>> 'margem_pct' in resultado.columns and 'ticket_medio' in resultado.columns\n",
        "True\n",
        ">>> resultado.index.name == 'categoria'\n",
        "True\n",
        "\"\"\",\n",
        "            \"hidden\": False,\n",
        "            \"locked\": False\n",
        "        }],\n",
        "        \"scored\": True,\n",
        "        \"setup\": \"\",\n",
        "        \"teardown\": \"\",\n",
        "        \"type\": \"doctest\"\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_grader"
      },
      "outputs": [],
      "source": [
        "# === CARREGAR OTTER GRADER ===\n",
        "\n",
        "import otter\n",
        "grader = otter.Notebook()\n",
        "\n",
        "print(\"‚úì Otter Grader carregado\")\n",
        "print(f\"‚úì Vers√£o: {otter.__version__}\")\n",
        "print(\"\\nüìö Testes dispon√≠veis: p1, p2, p3, p4, p5, p6, p7, p8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# === IMPORTAR BIBLIOTECAS ===\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Configurar exibi√ß√£o\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "# Seed para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"Pandas vers√£o: {pd.__version__}\")\n",
        "print(f\"NumPy vers√£o: {np.__version__}\")\n",
        "print(\"Bibliotecas carregadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_section"
      },
      "source": [
        "# === GERA√á√ÉO DE DADOS SINT√âTICOS ===\n",
        "\n",
        "Vamos criar dados realistas de um **e-commerce de tecnologia** para os exerc√≠cios.\n",
        "\n",
        "##Estrutura dos Dados\n",
        "\n",
        "### 1. Produtos\n",
        "- 20 produtos em 6 categorias\n",
        "- Pre√ßos e custos realistas\n",
        "\n",
        "### 2. Clientes\n",
        "- 10 clientes em diferentes cidades\n",
        "- Datas de cadastro variadas\n",
        "\n",
        "### 3. Vendas\n",
        "- 200 pedidos nos √∫ltimos 3 meses\n",
        "- Distribui√ß√£o realista de quantidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_data"
      },
      "outputs": [],
      "source": [
        "# === GERAR DADOS SINT√âTICOS ===\n",
        "\n",
        "# 1. PRODUTOS\n",
        "produtos = pd.DataFrame({\n",
        "    'produto_id': range(1, 21),\n",
        "    'nome_produto': [\n",
        "        'Mouse Gamer', 'Teclado Mec√¢nico', 'Monitor 24\"', 'Webcam HD',\n",
        "        'Headset', 'Mousepad', 'Hub USB', 'Cadeira Gamer',\n",
        "        'Mesa Ajust√°vel', 'Lumin√°ria LED', 'Suporte Monitor', 'Microfone',\n",
        "        'Caixa de Som', 'Cabo HDMI', 'Adaptador USB-C', 'SSD 500GB',\n",
        "        'Mem√≥ria RAM 16GB', 'HD Externo 1TB', 'Pen Drive 64GB', 'Case PC'\n",
        "    ],\n",
        "    'categoria': [\n",
        "        'Perif√©ricos', 'Perif√©ricos', 'Monitores', 'Perif√©ricos',\n",
        "        '√Åudio', 'Acess√≥rios', 'Acess√≥rios', 'M√≥veis',\n",
        "        'M√≥veis', 'Ilumina√ß√£o', 'Acess√≥rios', '√Åudio',\n",
        "        '√Åudio', 'Cabos', 'Cabos', 'Armazenamento',\n",
        "        'Hardware', 'Armazenamento', 'Armazenamento', 'Hardware'\n",
        "    ],\n",
        "    'preco': [\n",
        "        89.90, 299.90, 899.00, 249.90, 199.90, 49.90, 79.90, 1299.00,\n",
        "        1499.00, 149.90, 99.90, 399.90, 299.90, 29.90, 49.90, 399.90,\n",
        "        449.90, 399.90, 39.90, 299.90\n",
        "    ],\n",
        "    'custo': [\n",
        "        45.00, 150.00, 450.00, 125.00, 100.00, 25.00, 40.00, 650.00,\n",
        "        750.00, 75.00, 50.00, 200.00, 150.00, 15.00, 25.00, 200.00,\n",
        "        225.00, 200.00, 20.00, 150.00\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 2. CLIENTES\n",
        "nomes = ['Ana Silva', 'Bruno Costa', 'Carlos Santos', 'Diana Lima', 'Eduardo Souza',\n",
        "         'Fernanda Alves', 'Gabriel Oliveira', 'Helena Martins', 'Igor Ferreira', 'Julia Rocha']\n",
        "cidades = ['S√£o Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Curitiba']\n",
        "\n",
        "clientes = pd.DataFrame({\n",
        "    'cliente_id': range(1, 11),\n",
        "    'nome': nomes,\n",
        "    'cidade': np.random.choice(cidades, 10),\n",
        "    'data_cadastro': pd.date_range('2023-01-01', periods=10, freq='30D')\n",
        "})\n",
        "\n",
        "# 3. VENDAS (√∫ltimos 3 meses)\n",
        "n_vendas = 200\n",
        "data_inicio = datetime(2024, 8, 1)\n",
        "\n",
        "vendas = pd.DataFrame({\n",
        "    'pedido_id': range(1, n_vendas + 1),\n",
        "    'data': [data_inicio + timedelta(days=np.random.randint(0, 90)) for _ in range(n_vendas)],\n",
        "    'cliente_id': np.random.choice(clientes['cliente_id'], n_vendas),\n",
        "    'produto_id': np.random.choice(produtos['produto_id'], n_vendas),\n",
        "    'quantidade': np.random.choice([1, 1, 1, 2, 2, 3], n_vendas)\n",
        "})\n",
        "\n",
        "vendas = vendas.sort_values('data').reset_index(drop=True)\n",
        "\n",
        "print(\"Dados sint√©ticos criados!\")\n",
        "print(f\"Produtos: {len(produtos)} itens em {produtos['categoria'].nunique()} categorias\")\n",
        "print(f\"Clientes: {len(clientes)} pessoas\")\n",
        "print(f\"Vendas: {len(vendas)} pedidos\")\n",
        "print(f\"Per√≠odo: {vendas['data'].min().date()} a {vendas['data'].max().date()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview_data"
      },
      "outputs": [],
      "source": [
        "# === PR√âVIA DOS DADOS ===\n",
        "\n",
        "print(\"=== PRODUTOS (primeiros 5) ===\")\n",
        "print(produtos.head())\n",
        "\n",
        "print(\"\\n=== CLIENTES (primeiros 5) ===\")\n",
        "print(clientes.head())\n",
        "\n",
        "print(\"\\n=== VENDAS (primeiras 5) ===\")\n",
        "print(vendas.head())\n",
        "\n",
        "print(\"\\n=== CATEGORIAS DISPON√çVEIS ===\")\n",
        "print(produtos['categoria'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_base"
      },
      "outputs": [],
      "source": [
        "# === PREPARAR DATASET BASE ===\n",
        "\n",
        "# Combinar todas as informa√ß√µes em um √∫nico DataFrame\n",
        "df_completo = (\n",
        "    vendas\n",
        "    .merge(produtos, on='produto_id')\n",
        "    .merge(clientes, on='cliente_id')\n",
        "    .assign(\n",
        "        valor=lambda x: x['preco'] * x['quantidade'],\n",
        "        margem=lambda x: (x['preco'] - x['custo']) * x['quantidade']\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Dataset base preparado!\")\n",
        "print(f\"\\nShape: {df_completo.shape}\")\n",
        "print(f\"Colunas: {df_completo.columns.tolist()}\")\n",
        "\n",
        "print(\"\\n=== PRIMEIRAS LINHAS DO DATASET COMPLETO ===\")\n",
        "print(df_completo[['data', 'nome', 'nome_produto', 'categoria', 'quantidade', 'valor']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1_header"
      },
      "source": [
        "---\n",
        "\n",
        "# PR√ÅTICA 1: NAMED AGGREGATIONS\n",
        "\n",
        "## Bloco 1 - Transforma√ß√µes\n",
        "\n",
        "### Objetivo\n",
        "Usar **named aggregations** (Pandas 0.25+) para criar agrega√ß√µes com nomes descritivos.\n",
        "\n",
        "### O que s√£o Named Aggregations?\n",
        "\n",
        "**Antes** (sintaxe antiga):\n",
        "```python\n",
        "resultado = df.groupby('cat').agg({'val': ['sum', 'mean']})\n",
        "resultado.columns = ['_'.join(col) for col in resultado.columns]  # Renomear depois\n",
        "```\n",
        "\n",
        "**Agora** (sintaxe moderna):\n",
        "```python\n",
        "resultado = df.groupby('cat').agg(\n",
        "    total=('val', 'sum'),      # Nome claro direto!\n",
        "    media=('val', 'mean')\n",
        ")\n",
        "```\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Dado DataFrame de vendas, agrupar por **categoria** e calcular:\n",
        "- `valor_total`: soma total de vendas\n",
        "- `valor_medio`: ticket m√©dio\n",
        "- `num_vendas`: quantidade de transa√ß√µes\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "df.groupby('grupo').agg(\n",
        "    nome_descritivo=('coluna_original', 'funcao'),\n",
        "    outro_nome=('coluna', 'outra_funcao')\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1_code"
      },
      "outputs": [],
      "source": [
        "def agrupar_com_named_agg(df):\n",
        "    \"\"\"\n",
        "    Agrupa por categoria usando named aggregations.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com colunas 'categoria' e 'valor'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com agrega√ß√µes nomeadas\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    resultado = df.groupby('categoria').agg(\n",
        "        valor_total=('valor', 'sum'),\n",
        "        valor_medio=('valor', 'mean'),\n",
        "        num_vendas=('valor', 'count')\n",
        "    ).round(2)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1_test"
      },
      "outputs": [],
      "source": [
        "# Executar an√°lise\n",
        "analise_categoria = agrupar_com_named_agg(df_completo)\n",
        "\n",
        "print(\"=== AN√ÅLISE POR CATEGORIA ===\")\n",
        "print(analise_categoria.sort_values('valor_total', ascending=False))\n",
        "\n",
        "print(\"\\n=== TOP 3 CATEGORIAS ===\")\n",
        "top3 = analise_categoria.nlargest(3, 'valor_total')\n",
        "for categoria, row in top3.iterrows():\n",
        "    print(f\"{categoria}:\")\n",
        "    print(f\"    Faturamento: R$ {row['valor_total']:,.2f}\")\n",
        "    print(f\"    Ticket m√©dio: R$ {row['valor_medio']:.2f}\")\n",
        "    print(f\"    Vendas: {row['num_vendas']:.0f}\")\n",
        "    print()\n",
        "\n",
        "print(\"Observe como os nomes das colunas s√£o descritivos e leg√≠veis!\")\n",
        "print(\"N√£o foi necess√°rio renomear depois do groupby.\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 2: BINNING COM QCUT\n",
        "\n",
        "## Bloco 1 - Transforma√ß√µes\n",
        "\n",
        "### Objetivo\n",
        "Criar **faixas balanceadas** de valor usando `pd.qcut()`.\n",
        "\n",
        "### cut() vs qcut()\n",
        "\n",
        "| M√©todo | O que faz | Quando usar |\n",
        "|--------|-----------|-------------|\n",
        "| **cut()** | Intervalos de **largura igual** | Limites fixos (ex: idades 0-18, 18-65) |\n",
        "| **qcut()** | Intervalos com **frequ√™ncia igual** | Distribui√ß√£o balanceada (quartis) |\n",
        "\n",
        "### Exemplo Visual\n",
        "\n",
        "Valores: `[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]`\n",
        "\n",
        "**cut(bins=3)**: Intervalos fixos\n",
        "- [10-40]: 3 valores - desbalanceado\n",
        "- [40-70]: 3 valores\n",
        "- [70-100]: 4 valores\n",
        "\n",
        "**qcut(q=3)**: Frequ√™ncia igual\n",
        "- Q1: 3-4 valores - balanceado\n",
        "- Q2: 3-4 valores\n",
        "- Q3: 3-4 valores\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Criar coluna `faixa` dividindo valores de vendas em **4 quartis**:\n",
        "- Q1-Baixo\n",
        "- Q2-Medio-Baixo\n",
        "- Q3-Medio-Alto\n",
        "- Q4-Alto\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "pd.qcut(\n",
        "    df['coluna'],\n",
        "    q=4,  # 4 quartis\n",
        "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2_code"
      },
      "outputs": [],
      "source": [
        "def criar_faixas_balanceadas(df):\n",
        "    \"\"\"\n",
        "    Cria quartis (faixas balanceadas) de valor.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com coluna 'valor'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com coluna 'faixa' adicionada\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    df_novo = df.copy()\n",
        "\n",
        "    df_novo['faixa'] = pd.qcut(\n",
        "        df_novo['valor'],\n",
        "        q=4,\n",
        "        labels=['Q1-Baixo', 'Q2-Medio-Baixo', 'Q3-Medio-Alto', 'Q4-Alto']\n",
        "    )\n",
        "\n",
        "    return df_novo\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2_test"
      },
      "outputs": [],
      "source": [
        "# Criar faixas\n",
        "df_com_faixas = criar_faixas_balanceadas(df_completo)\n",
        "\n",
        "print(\"=== DISTRIBUI√á√ÉO POR FAIXA ===\")\n",
        "distribuicao = df_com_faixas['faixa'].value_counts().sort_index()\n",
        "print(distribuicao)\n",
        "\n",
        "print(\"\\n=== ESTAT√çSTICAS POR FAIXA ===\")\n",
        "stats_faixa = df_com_faixas.groupby('faixa', observed=True).agg(\n",
        "    valor_min=('valor', 'min'),\n",
        "    valor_max=('valor', 'max'),\n",
        "    valor_medio=('valor', 'mean'),\n",
        "    contagem=('valor', 'count')\n",
        ").round(2)\n",
        "print(stats_faixa)\n",
        "\n",
        "print(\"\\n  OBSERVE:\")\n",
        "print(\"     Cada faixa tem aproximadamente o mesmo n√∫mero de pedidos\")\n",
        "print(\"     Mas os intervalos de valor t√™m tamanhos diferentes\")\n",
        "print(\"\\n   Isso √© diferente de pd.cut() que cria intervalos de tamanho igual!\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 3: WINDOW FUNCTIONS - VARIA√á√ÉO PERCENTUAL\n",
        "\n",
        "## Bloco 2 - GroupBy e Window Functions\n",
        "\n",
        "### Objetivo\n",
        "Calcular **varia√ß√£o percentual** entre per√≠odos usando `pct_change()`.\n",
        "\n",
        "### O que s√£o Window Functions?\n",
        "\n",
        "Opera√ß√µes que consideram valores \"vizinhos\" sem agregar:\n",
        "\n",
        "| Fun√ß√£o | O que faz | Exemplo |\n",
        "|--------|-----------|----------|\n",
        "| `shift(1)` | Valor anterior | Comparar com m√™s passado |\n",
        "| `diff()` | Diferen√ßa absoluta | Crescimento em R$ |\n",
        "| `pct_change()` | Varia√ß√£o percentual | Crescimento em % |\n",
        "| `rolling(3).mean()` | M√©dia m√≥vel | Tend√™ncia suavizada |\n",
        "\n",
        "### Exemplo\n",
        "\n",
        "```python\n",
        "vendas = [100, 120, 110, 140]\n",
        "\n",
        "# Valor anterior\n",
        "shift(1):      [NaN, 100, 120, 110]\n",
        "\n",
        "# Diferen√ßa\n",
        "diff():        [NaN, +20, -10, +30]\n",
        "\n",
        "# Varia√ß√£o %\n",
        "pct_change():  [NaN, +20%, -8.3%, +27.3%]\n",
        "```\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Dado vendas mensais, adicionar coluna `variacao_pct` com crescimento m√™s-a-m√™s.\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "df['variacao_pct'] = df['valor'].pct_change() * 100  # Percentual\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3_code"
      },
      "outputs": [],
      "source": [
        "def calcular_variacao_percentual(df):\n",
        "    \"\"\"\n",
        "    Calcula varia√ß√£o percentual m√™s-a-m√™s.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com colunas 'mes' e 'vendas'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com coluna 'variacao_pct'\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    df_novo = df.copy()\n",
        "\n",
        "    df_novo['variacao_pct'] = (df_novo['vendas'].pct_change() * 100).round(2)\n",
        "\n",
        "    return df_novo\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3_test"
      },
      "outputs": [],
      "source": [
        "# Preparar dados mensais\n",
        "vendas_mensais = (\n",
        "    df_completo\n",
        "    .assign(mes=lambda x: x['data'].dt.to_period('M'))\n",
        "    .groupby('mes')\n",
        "    .agg(\n",
        "        vendas=('valor', 'sum'),\n",
        "        num_pedidos=('pedido_id', 'count')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"=== VENDAS MENSAIS (ANTES) ===\")\n",
        "print(vendas_mensais)\n",
        "\n",
        "# Calcular varia√ß√£o\n",
        "vendas_com_variacao = calcular_variacao_percentual(vendas_mensais)\n",
        "\n",
        "print(\"\\n=== VENDAS MENSAIS (DEPOIS) ===\")\n",
        "print(vendas_com_variacao)\n",
        "\n",
        "print(\"\\n=== AN√ÅLISE DE CRESCIMENTO ===\")\n",
        "crescimento_medio = vendas_com_variacao['variacao_pct'].mean()\n",
        "print(f\"Crescimento m√©dio mensal: {crescimento_medio:.2f}%\")\n",
        "\n",
        "# Melhor e pior m√™s\n",
        "melhor_idx = vendas_com_variacao['variacao_pct'].idxmax()\n",
        "if not pd.isna(vendas_com_variacao.loc[melhor_idx, 'variacao_pct']):\n",
        "    melhor = vendas_com_variacao.loc[melhor_idx]\n",
        "    print(f\"\\n Melhor crescimento: {melhor['mes']} ({melhor['variacao_pct']:.2f}%)\")\n",
        "\n",
        "pior_idx = vendas_com_variacao['variacao_pct'].idxmin()\n",
        "if not pd.isna(vendas_com_variacao.loc[pior_idx, 'variacao_pct']):\n",
        "    pior = vendas_com_variacao.loc[pior_idx]\n",
        "    print(f\" Pior crescimento: {pior['mes']} ({pior['variacao_pct']:.2f}%)\")\n",
        "\n",
        "print(\"\\n pct_change() automaticamente compara com per√≠odo anterior!\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 4: RANKING DENTRO DE GRUPOS\n",
        "\n",
        "## Bloco 2 - GroupBy e Window Functions\n",
        "\n",
        "### Objetivo\n",
        "Criar **ranking** de produtos mais vendidos **dentro de cada categoria**.\n",
        "\n",
        "### Por que Ranking?\n",
        "\n",
        "Rankings permitem responder:\n",
        "- Top 3 produtos por categoria\n",
        "- Quais clientes gastaram mais em cada regi√£o\n",
        "- Ranking de vendedores por trimestre\n",
        "\n",
        "### M√©todos de Ranking\n",
        "\n",
        "```python\n",
        "valores = [100, 90, 90, 80]\n",
        "\n",
        "method='average': [1, 2.5, 2.5, 4]  # M√©dia das posi√ß√µes\n",
        "method='min':     [1, 2, 2, 4]      # Menor posi√ß√£o\n",
        "method='max':     [1, 3, 3, 4]      # Maior posi√ß√£o\n",
        "method='dense':   [1, 2, 2, 3]      # Sem gaps (melhor!)\n",
        "method='first':   [1, 2, 3, 4]      # Ordem de apari√ß√£o\n",
        "```\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Adicionar coluna `rank` com ranking de valor **dentro de cada categoria**:\n",
        "- Rank 1 = maior valor\n",
        "- method='dense' (sem gaps)\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "df['rank'] = df.groupby('grupo')['valor'].rank(\n",
        "    ascending=False,  # Maior = rank 1\n",
        "    method='dense'    # Sem gaps: 1, 2, 3, ...\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4_code"
      },
      "outputs": [],
      "source": [
        "def criar_ranking_por_grupo(df):\n",
        "    \"\"\"\n",
        "    Cria ranking de valor dentro de cada categoria.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com colunas 'categoria' e 'valor'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com coluna 'rank'\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    df_novo = df.copy()\n",
        "\n",
        "    df_novo['rank'] = df_novo.groupby('categoria')['valor'].rank(\n",
        "        ascending=False,\n",
        "        method='dense'\n",
        "    ).astype(int)\n",
        "\n",
        "    return df_novo\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4_test"
      },
      "outputs": [],
      "source": [
        "# Preparar vendas por produto\n",
        "vendas_produto = (\n",
        "    df_completo\n",
        "    .groupby(['categoria', 'nome_produto'])\n",
        "    .agg(\n",
        "        valor=('valor', 'sum'),\n",
        "        quantidade=('quantidade', 'sum')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"=== VENDAS POR PRODUTO (antes do ranking) ===\")\n",
        "print(vendas_produto.head(10))\n",
        "\n",
        "# Criar ranking\n",
        "vendas_com_rank = criar_ranking_por_grupo(vendas_produto)\n",
        "\n",
        "print(\"\\n=== TOP 3 POR CATEGORIA ===\")\n",
        "top3 = (\n",
        "    vendas_com_rank\n",
        "    .query('rank <= 3')\n",
        "    .sort_values(['categoria', 'rank'])\n",
        ")\n",
        "\n",
        "for categoria in top3['categoria'].unique():\n",
        "    print(f\"\\n {categoria}:\")\n",
        "    dados_cat = top3[top3['categoria'] == categoria]\n",
        "    for _, row in dados_cat.iterrows():\n",
        "        print(f\"  {row['rank']}¬∫ - {row['nome_produto']}: R$ {row['valor']:,.2f}\")\n",
        "\n",
        "print(\"\\n O ranking √© calculado DENTRO de cada categoria separadamente!\")\n",
        "print(\"   Cada categoria tem seu pr√≥prio Top 1, Top 2, Top 3...\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 5: MERGE COM VALIDA√á√ÉO\n",
        "\n",
        "## Bloco 3 - Combina√ß√£o de DataFrames\n",
        "\n",
        "### Objetivo\n",
        "Fazer merge entre DataFrames com **valida√ß√£o de relacionamento**.\n",
        "\n",
        "### O Problema\n",
        "\n",
        "Merge pode **duplicar linhas silenciosamente** se houver IDs duplicados:\n",
        "\n",
        "```python\n",
        "# Clientes com ID duplicado (ERRO!)\n",
        "df1 = DataFrame({'id': [1, 2, 2], 'nome': ['Ana', 'Bruno', 'Bruno Jr']})\n",
        "df2 = DataFrame({'id': [1, 2], 'valor': [100, 200]})\n",
        "\n",
        "# Merge SEM valida√ß√£o: aceita, mas duplica!\n",
        "merge(df1, df2)  # 3 linhas (deveria dar erro!)\n",
        "```\n",
        "\n",
        "### A Solu√ß√£o: validate\n",
        "\n",
        "```python\n",
        "pd.merge(df1, df2, on='id', validate='1:1')\n",
        "# MergeError: Merge keys are not unique!\n",
        "```\n",
        "\n",
        "### Tipos de Relacionamento\n",
        "\n",
        "| validate | Significado | Exemplo |\n",
        "|----------|-------------|----------|\n",
        "| `'1:1'` | Um-para-um | Cliente ‚Üî Endere√ßo |\n",
        "| `'1:m'` | Um-para-muitos | Cliente ‚Üí Pedidos |\n",
        "| `'m:1'` | Muitos-para-um | Produtos ‚Üí Categoria |\n",
        "| `'m:m'` | Muitos-para-muitos | Produtos ‚Üî Tags |\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Fazer merge validado (1:1) entre clientes e seus totais de compra.\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "pd.merge(df1, df2, on='id', validate='1:1')\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5_code"
      },
      "outputs": [],
      "source": [
        "def fazer_merge_validado(df1, df2):\n",
        "    \"\"\"\n",
        "    Faz merge com valida√ß√£o de relacionamento 1:1.\n",
        "\n",
        "    Args:\n",
        "        df1, df2: DataFrames com coluna 'id' comum\n",
        "\n",
        "    Returns:\n",
        "        DataFrame resultante do merge validado\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    resultado = pd.merge(\n",
        "        df1, df2,\n",
        "        on='id',\n",
        "        how='inner',\n",
        "        validate='1:1'  # Valida relacionamento um-para-um\n",
        "    )\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5_test"
      },
      "outputs": [],
      "source": [
        "# Preparar dados\n",
        "df_completo = (\n",
        "    vendas\n",
        "    .merge(produtos, on='produto_id')\n",
        "    .merge(clientes, on='cliente_id')\n",
        "    .assign(valor=lambda x: x['preco'] * x['quantidade'])\n",
        ")\n",
        "\n",
        "# Totais por cliente\n",
        "totais_cliente = (\n",
        "    df_completo\n",
        "    .groupby('cliente_id')\n",
        "    .agg(\n",
        "        total_gasto=('valor', 'sum'),\n",
        "        num_compras=('pedido_id', 'count'),\n",
        "        ticket_medio=('valor', 'mean')\n",
        "    )\n",
        "    .reset_index()\n",
        "    .rename(columns={'cliente_id': 'id'})\n",
        ")\n",
        "\n",
        "clientes_renomeado = clientes.rename(columns={'cliente_id': 'id'})\n",
        "\n",
        "print(\"=== CLIENTES ===\")\n",
        "print(clientes_renomeado[['id', 'nome', 'cidade']].head())\n",
        "\n",
        "print(\"\\n=== TOTAIS POR CLIENTE ===\")\n",
        "print(totais_cliente.head())\n",
        "\n",
        "# Merge validado\n",
        "try:\n",
        "    clientes_completo = fazer_merge_validado(clientes_renomeado, totais_cliente)\n",
        "\n",
        "    print(\"\\n MERGE VALIDADO COM SUCESSO!\")\n",
        "    print(\"   Nenhuma duplicata detectada.\")\n",
        "\n",
        "    print(\"\\n=== RESULTADO DO MERGE ===\")\n",
        "    print(clientes_completo[['nome', 'cidade', 'total_gasto', 'num_compras', 'ticket_medio']]\n",
        "          .sort_values('total_gasto', ascending=False))\n",
        "\n",
        "    print(\"\\n=== TOP 3 CLIENTES ===\")\n",
        "    top3 = clientes_completo.nlargest(3, 'total_gasto')\n",
        "    for i, row in enumerate(top3.itertuples(), 1):\n",
        "        print(f\"{i}¬∫ {row.nome} ({row.cidade}):\")\n",
        "        print(f\"   Total: R$ {row.total_gasto:,.2f}\")\n",
        "        print(f\"   Compras: {row.num_compras:.0f}\")\n",
        "        print(f\"   Ticket: R$ {row.ticket_medio:.2f}\")\n",
        "        print()\n",
        "\n",
        "except pd.errors.MergeError as e:\n",
        "    print(f\"\\n ERRO NO MERGE: {e}\")\n",
        "    print(\"   IDs duplicados detectados!\")\n",
        "\n",
        "print(\"üí° O par√¢metro validate='1:1' previne merges problem√°ticos!\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 6: PIVOT TABLE AVAN√áADO\n",
        "\n",
        "## Bloco 4 - Reshape e Pivot\n",
        "\n",
        "### Objetivo\n",
        "Criar **pivot table** com m√∫ltiplas agrega√ß√µes.\n",
        "\n",
        "### O que √© Pivot Table?\n",
        "\n",
        "Reorganiza dados em formato de **matriz bidimensional**:\n",
        "\n",
        "**Antes** (formato longo):\n",
        "```\n",
        "Categoria     M√™s    Vendas\n",
        "Perif√©ricos   Jan    1000\n",
        "Perif√©ricos   Fev    1200\n",
        "√Åudio         Jan    800\n",
        "√Åudio         Fev    900\n",
        "```\n",
        "\n",
        "**Depois** (pivot):\n",
        "```\n",
        "              Jan    Fev\n",
        "Perif√©ricos  1000   1200\n",
        "√Åudio         800    900\n",
        "```\n",
        "\n",
        "### Quando Usar?\n",
        "\n",
        "- An√°lise temporal (vendas por m√™s)\n",
        "- Compara√ß√£o cruzada (regi√£o √ó produto)\n",
        "- Dashboards e relat√≥rios\n",
        "- Heatmaps de correla√ß√£o\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Criar pivot table: **categoria** (linhas) √ó **m√™s** (colunas), agregando vendas.\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "pd.pivot_table(\n",
        "    df,\n",
        "    values='valor',\n",
        "    index='linhas',\n",
        "    columns='colunas',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0  # Preencher vazios\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 7 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6_code"
      },
      "outputs": [],
      "source": [
        "def criar_pivot_avancado(df):\n",
        "    \"\"\"\n",
        "    Cria pivot table: categoria √ó m√™s.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com 'categoria', 'mes', 'vendas'\n",
        "\n",
        "    Returns:\n",
        "        Pivot table\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    pivot = pd.pivot_table(\n",
        "        df,\n",
        "        values='vendas',\n",
        "        index='categoria',\n",
        "        columns='mes',\n",
        "        aggfunc='sum',\n",
        "        fill_value=0\n",
        "    )\n",
        "\n",
        "    return pivot\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6_test"
      },
      "outputs": [],
      "source": [
        "# Preparar dados\n",
        "vendas_cat_mes = (\n",
        "    df_completo\n",
        "    .assign(mes=lambda x: x['data'].dt.to_period('M'))\n",
        "    .groupby(['categoria', 'mes'])\n",
        "    .agg(vendas=('valor', 'sum'))\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"=== DADOS AGREGADOS (formato longo) ===\")\n",
        "print(vendas_cat_mes.head(10))\n",
        "\n",
        "# Criar pivot\n",
        "pivot = criar_pivot_avancado(vendas_cat_mes)\n",
        "\n",
        "print(\"\\n=== PIVOT TABLE: CATEGORIA √ó M√äS ===\")\n",
        "print(pivot)\n",
        "\n",
        "print(\"\\n=== AN√ÅLISE ===\")\n",
        "print(\"\\n Total por categoria:\")\n",
        "total_cat = pivot.sum(axis=1).sort_values(ascending=False)\n",
        "for cat, total in total_cat.head(3).items():\n",
        "    print(f\"  {cat}: R$ {total:,.2f}\")\n",
        "\n",
        "print(\"\\n Total por m√™s:\")\n",
        "total_mes = pivot.sum(axis=0)\n",
        "for mes, total in total_mes.items():\n",
        "    print(f\"  {mes}: R$ {total:,.2f}\")\n",
        "\n",
        "print(\"\\n Pivot table facilita an√°lise temporal e compara√ß√µes cruzadas!\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 7: TRANSFORM - NORMALIZA√á√ÉO POR GRUPO\n",
        "\n",
        "## Bloco 4 - Reshape e Transform\n",
        "\n",
        "### Objetivo\n",
        "Normalizar valores **dentro de cada grupo** usando **Z-score**.\n",
        "\n",
        "### transform() vs aggregate()\n",
        "\n",
        "| M√©todo | Shape do resultado | Uso |\n",
        "|--------|-------------------|------|\n",
        "| **agg()** | Reduz linhas | Estat√≠sticas resumidas |\n",
        "| **transform()** | Mant√©m linhas | Adicionar estat√≠sticas ao original |\n",
        "\n",
        "**Exemplo:**\n",
        "```python\n",
        "df = DataFrame({'grupo': ['A','A','B','B'], 'valor': [10,20,30,40]})\n",
        "\n",
        "# agg: reduz (2 linhas)\n",
        "df.groupby('grupo')['valor'].agg('mean')\n",
        "# A    15\n",
        "# B    35\n",
        "\n",
        "# transform: mant√©m (4 linhas)\n",
        "df.groupby('grupo')['valor'].transform('mean')\n",
        "# [15, 15, 35, 35]  <- pode adicionar como coluna!\n",
        "```\n",
        "\n",
        "### O que √© Z-score?\n",
        "\n",
        "Normaliza√ß√£o que indica **quantos desvios-padr√£o** um valor est√° da m√©dia:\n",
        "\n",
        "```\n",
        "z = (valor - m√©dia) / desvio_padr√£o\n",
        "```\n",
        "\n",
        "**Interpreta√ß√£o:**\n",
        "- `z > 0`: Acima da m√©dia\n",
        "- `z = 0`: Na m√©dia\n",
        "- `z < 0`: Abaixo da m√©dia\n",
        "- `|z| > 2`: Outlier (muito diferente)\n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Criar coluna `valor_normalizado` com Z-score **dentro de cada grupo**.\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "df['norm'] = df.groupby('grupo')['valor'].transform(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 8 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7_code"
      },
      "outputs": [],
      "source": [
        "def normalizar_por_grupo(df):\n",
        "    \"\"\"\n",
        "    Normaliza valores (Z-score) dentro de cada grupo.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame com 'grupo' e 'valor'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com 'valor_normalizado'\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    df_novo = df.copy()\n",
        "\n",
        "    df_novo['valor_normalizado'] = df_novo.groupby('grupo')['valor'].transform(\n",
        "        lambda x: ((x - x.mean()) / x.std()).round(2)\n",
        "    )\n",
        "\n",
        "    return df_novo\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7_test"
      },
      "outputs": [],
      "source": [
        "# Preparar dados\n",
        "vendas_produto = (\n",
        "    df_completo\n",
        "    .groupby(['categoria', 'produto_id', 'nome_produto'])\n",
        "    .agg(valor=('valor', 'sum'))\n",
        "    .reset_index()\n",
        "    .rename(columns={'categoria': 'grupo'})\n",
        ")\n",
        "\n",
        "print(\"=== VENDAS POR PRODUTO (antes) ===\")\n",
        "print(vendas_produto[['grupo', 'nome_produto', 'valor']].head(10))\n",
        "\n",
        "# Normalizar\n",
        "vendas_norm = normalizar_por_grupo(vendas_produto)\n",
        "\n",
        "print(\"\\n=== COM VALORES NORMALIZADOS ===\")\n",
        "print(vendas_norm[['grupo', 'nome_produto', 'valor', 'valor_normalizado']].head(15))\n",
        "\n",
        "print(\"\\n=== INTERPRETA√á√ÉO DO Z-SCORE ===\")\n",
        "print(\"  z > 0  : Produto vende MAIS que a m√©dia da categoria\")\n",
        "print(\"  z = 0  : Produto na m√©dia da categoria\")\n",
        "print(\"  z < 0  : Produto vende MENOS que a m√©dia\")\n",
        "print(\"  |z| > 2: OUTLIER (muito diferente da m√©dia)\")\n",
        "\n",
        "# Encontrar outliers\n",
        "outliers = vendas_norm[vendas_norm['valor_normalizado'].abs() > 2]\n",
        "if len(outliers) > 0:\n",
        "    print(f\"\\n OUTLIERS DETECTADOS ({len(outliers)}):\")\n",
        "    for _, row in outliers.iterrows():\n",
        "        tipo = \" MUITO ACIMA\" if row['valor_normalizado'] > 0 else \"üìâ MUITO ABAIXO\"\n",
        "        print(f\"{tipo} - {row['nome_produto']} ({row['grupo']})\")\n",
        "        print(f\"  Valor: R$ {row['valor']:,.2f} | Z-score: {row['valor_normalizado']}\")\n",
        "else:\n",
        "    print(\"\\n Nenhum outlier detectado (todos dentro de 2 desvios-padr√£o).\")\n",
        "\n",
        "print(\"\\n transform() mant√©m todas as linhas originais!\")\n",
        "print(f\"   Linhas antes: {len(vendas_produto)}\")\n",
        "print(f\"   Linhas depois: {len(vendas_norm)}\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8_header"
      },
      "source": [
        "---\n",
        "\n",
        "#PR√ÅTICA 8: PIPELINE COMPLETO COM METHOD CHAINING\n",
        "\n",
        "## Bloco 4 - Method Chaining\n",
        "\n",
        "### Objetivo\n",
        "Construir **pipeline completo** usando method chaining.\n",
        "\n",
        "### O que √© Method Chaining?\n",
        "\n",
        "Encadear opera√ß√µes em uma √∫nica express√£o:\n",
        "\n",
        "**Antes** (m√∫ltiplas vari√°veis):\n",
        "```python\n",
        "df1 = df.dropna()\n",
        "df2 = df1.query('valor > 0')\n",
        "df3 = df2.assign(nova=lambda x: x['a'] * 2)\n",
        "df4 = df3.groupby('cat').agg({'nova': 'sum'})\n",
        "resultado = df4.sort_values('nova', ascending=False)\n",
        "```\n",
        "\n",
        "**Depois** (pipeline):\n",
        "```python\n",
        "resultado = (\n",
        "    df\n",
        "    .dropna()\n",
        "    .query('valor > 0')\n",
        "    .assign(nova=lambda x: x['a'] * 2)\n",
        "    .groupby('cat')\n",
        "    .agg({'nova': 'sum'})\n",
        "    .sort_values('nova', ascending=False)\n",
        ")\n",
        "```\n",
        "\n",
        "### Vantagens\n",
        "\n",
        "- C√≥digo mais leg√≠vel  \n",
        "- F√°cil adicionar/remover etapas  \n",
        "- Sem vari√°veis intermedi√°rias  \n",
        "- Fluxo claro de transforma√ß√µes  \n",
        "\n",
        "### Tarefa\n",
        "\n",
        "Criar pipeline que:\n",
        "1. Calcula margem\n",
        "2. Agrupa por categoria (named agg)\n",
        "3. Calcula margem percentual\n",
        "4. Ordena por receita\n",
        "\n",
        "### Dicas\n",
        "```python\n",
        "resultado = (\n",
        "    df\n",
        "    .assign(nova=...)\n",
        "    .groupby('grupo').agg(...)\n",
        "    .sort_values(...)\n",
        ")\n",
        "```\n",
        "\n",
        "**Tempo:** 10 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8_code"
      },
      "outputs": [],
      "source": [
        "def pipeline_completo(df):\n",
        "    \"\"\"\n",
        "    Pipeline completo de an√°lise com method chaining.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame de vendas completo\n",
        "\n",
        "    Returns:\n",
        "        An√°lise agregada e ordenada\n",
        "    \"\"\"\n",
        "    # === SEU C√ìDIGO AQUI ===\n",
        "\n",
        "    # Calcular margem se n√£o existir\n",
        "    if 'margem' not in df.columns and 'preco' in df.columns:\n",
        "        df = df.assign(\n",
        "            valor=lambda x: x['preco'] * x.get('quantidade', 1),\n",
        "            margem=lambda x: (x['preco'] - x.get('custo', 0)) * x.get('quantidade', 1)\n",
        "        )\n",
        "\n",
        "    resultado = (\n",
        "        df\n",
        "        # Agrupar por categoria com named aggregations\n",
        "        .groupby('categoria')\n",
        "        .agg(\n",
        "            receita_total=('valor', 'sum'),\n",
        "            margem_total=('margem', 'sum'),\n",
        "            ticket_medio=('valor', 'mean'),\n",
        "            num_vendas=('valor', 'count')\n",
        "        )\n",
        "        # Calcular margem percentual\n",
        "        .assign(\n",
        "            margem_pct=lambda x: (x['margem_total'] / x['receita_total'] * 100).round(2)\n",
        "        )\n",
        "        # Ordenar por receita\n",
        "        .sort_values('receita_total', ascending=False)\n",
        "        # Arredondar\n",
        "        .round(2)\n",
        "    )\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU C√ìDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8_test"
      },
      "outputs": [],
      "source": [
        "# Executar pipeline\n",
        "analise_final = pipeline_completo(df_completo)\n",
        "\n",
        "print(\"=== AN√ÅLISE FINAL POR CATEGORIA ===\")\n",
        "print(analise_final)\n",
        "\n",
        "print(\"\\n=== INSIGHTS DE NEG√ìCIO ===\")\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£ CATEGORIA MAIS LUCRATIVA:\")\n",
        "top1 = analise_final.iloc[0]\n",
        "print(f\"   {analise_final.index[0]}\")\n",
        "print(f\"   Receita: R$ {top1['receita_total']:,.2f}\")\n",
        "print(f\"   Margem: R$ {top1['margem_total']:,.2f} ({top1['margem_pct']:.1f}%)\")\n",
        "print(f\"   Ticket m√©dio: R$ {top1['ticket_medio']:.2f}\")\n",
        "\n",
        "melhor_margem = analise_final['margem_pct'].idxmax()\n",
        "print(f\"\\n2Ô∏è MELHOR MARGEM PERCENTUAL:\")\n",
        "print(f\"    {melhor_margem}\")\n",
        "print(f\"    {analise_final.loc[melhor_margem, 'margem_pct']:.1f}%\")\n",
        "\n",
        "maior_ticket = analise_final['ticket_medio'].idxmax()\n",
        "print(f\"\\n3Ô∏è MAIOR TICKET M√âDIO:\")\n",
        "print(f\"    {maior_ticket}\")\n",
        "print(f\"    R$ {analise_final.loc[maior_ticket, 'ticket_medio']:,.2f}\")\n",
        "\n",
        "print(\"\\n TODO O PIPELINE FOI EXECUTADO EM UMA √öNICA EXPRESS√ÉO!\")\n",
        "print(\"   Sem vari√°veis intermedi√°rias, c√≥digo limpo e leg√≠vel.\")\n",
        "\n",
        "# Teste\n",
        "grader.check(\"p8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "---\n",
        "\n",
        "#RESUMO\n",
        "\n",
        "##O que voc√™ aprendeu:\n",
        "\n",
        "### Pr√°tica 1 - Named Aggregations\n",
        "```python\n",
        "df.groupby('grupo').agg(\n",
        "    nome_claro=('coluna', 'funcao')\n",
        ")\n",
        "```\n",
        "=> C√≥digo mais leg√≠vel e profissional\n",
        "\n",
        "### Pr√°tica 2 - Binning com qcut\n",
        "```python\n",
        "pd.qcut(df['valor'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
        "```\n",
        "Faixas balanceadas (frequ√™ncia igual)\n",
        "\n",
        "### Pr√°tica 3 - Varia√ß√£o Percentual\n",
        "```python\n",
        "df['variacao'] = df['valor'].pct_change() * 100\n",
        "```\n",
        "Crescimento m√™s-a-m√™s automaticamente\n",
        "\n",
        "### Pr√°tica 4 - Ranking por Grupo\n",
        "```python\n",
        "df.groupby('grupo')['valor'].rank(ascending=False, method='dense')\n",
        "```\n",
        "Top N dentro de cada categoria\n",
        "\n",
        "### Pr√°tica 5 - Merge com Valida√ß√£o\n",
        "```python\n",
        "pd.merge(df1, df2, on='id', validate='1:1')\n",
        "```\n",
        "Previne duplica√ß√£o silenciosa de dados\n",
        "\n",
        "### Pr√°tica 6 - Pivot Table\n",
        "```python\n",
        "pd.pivot_table(df, values='val', index='lin', columns='col', aggfunc='sum')\n",
        "```\n",
        "Matriz bidimensional para an√°lise cruzada\n",
        "\n",
        "### Pr√°tica 7 - Transform e Normaliza√ß√£o\n",
        "```python\n",
        "df.groupby('grupo')['valor'].transform(lambda x: (x - x.mean()) / x.std())\n",
        "```\n",
        "Normaliza√ß√£o dentro de grupos, detecta outliers\n",
        "\n",
        "### Pr√°tica 8 - Method Chaining\n",
        "```python\n",
        "(df\n",
        " .assign(nova=...)\n",
        " .groupby('grupo').agg(...)\n",
        " .sort_values(...))\n",
        "```\n",
        "Pipeline completo em uma express√£o\n",
        "---\n",
        "\n",
        "##Conceitos-Chave\n",
        "\n",
        "| Conceito | Quando Usar |\n",
        "|----------|-------------|\n",
        "| **Named agg** | Sempre! C√≥digo mais leg√≠vel |\n",
        "| **qcut()** | Quartis, distribui√ß√£o balanceada |\n",
        "| **cut()** | Intervalos fixos (ex: idades) |\n",
        "| **pct_change()** | Crescimento percentual |\n",
        "| **rank()** | Top N, classifica√ß√µes |\n",
        "| **validate** | Sempre em produ√ß√£o! |\n",
        "| **pivot_table** | An√°lise temporal, cruzada |\n",
        "| **transform** | Adicionar stats mantendo shape |\n",
        "| **Z-score** | Detectar outliers |\n",
        "| **Method chaining** | Pipelines limpos |\n",
        "\n",
        "---\n",
        "\n",
        "##Pr√≥ximo Passo\n",
        "\n",
        "Agora voc√™ est√° pronto para o **PROJETO REAL**:\n",
        "- Pipeline completo de an√°lise\n",
        "- Dados realistas de e-commerce\n",
        "- 35-40 minutos de live coding\n",
        "- Todos os conceitos integrados"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}