# -*- coding: utf-8 -*-
"""notebook_exercicio_aula09.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PQkNM9kaQfAuwtdYczDA-sWzA8LikP_3

# Aula 09 - Exercício: Limpeza e Tratamento de Dados
**Curso:** Programação para Ciência de Dados  
**Aluno:** Gisele Fonseca
**Data:** 04 de novembro

## Instruções
1. Complete todos os exercícios marcados com `# === SEU CÓDIGO AQUI ===`
2. Execute as células de teste para verificar suas respostas
3. **Tempo estimado total:** 35 minutos

## Critérios de Avaliação
- **Conteúdo (100%):** Testes automáticos

## Objetivo
Consolidar conhecimentos de limpeza de dados através de exercícios práticos com um dataset real de e-commerce.
"""

# === CONFIGURAÇÃO INICIAL ===

!pip install --upgrade pip --quiet
!pip cache purge
!pip install otter-grader --no-cache-dir -q
!mkdir -p tests

print("Ambiente configurado!")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/q1.py
# OK_FORMAT = True
# 
# test = {
#     "name": "q1",
#     "points": 3,
#     "suites": [
#         {
#             "cases": [
#                 {
#                     "code": r"""
# >>> # Teste 1: Retorna DataFrame
# >>> import pandas as pd
# >>> isinstance(missing_report, pd.DataFrame)
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 },
#                 {
#                     "code": r"""
# >>> # Teste 2: Tem colunas corretas
# >>> 'Missing_Count' in missing_report.columns and 'Missing_Pct' in missing_report.columns
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 }
#             ],
#             "scored": True,
#             "setup": "",
#             "teardown": "",
#             "type": "doctest"
#         }
#     ]
# }

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/q2.py
# OK_FORMAT = True
# 
# test = {
#     "name": "q2",
#     "points": 3,
#     "suites": [
#         {
#             "cases": [
#                 {
#                     "code": r"""
# >>> # Teste 1: Strings limpas
# >>> bool(df['status'].str.contains(' ').sum() == 0)
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 },
#                 {
#                     "code": r"""
# >>> # Teste 2: Padronizado para minúsculo
# >>> bool(df['status'].str.islower().all())
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 }
#             ],
#             "scored": True,
#             "setup": "",
#             "teardown": "",
#             "type": "doctest"
#         }
#     ]
# }

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/q3.py
# OK_FORMAT = True
# 
# test = {
#     "name": "q3",
#     "points": 3,
#     "suites": [
#         {
#             "cases": [
#                 {
#                     "code": r"""
# >>> # Teste 1: Quantity é numérico
# >>> import pandas as pd
# >>> bool(pd.api.types.is_numeric_dtype(df['quantity']))
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 },
#                 {
#                     "code": r"""
# >>> # Teste 2: Sem valores negativos
# >>> bool((df['quantity'].dropna() >= 0).all())
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 }
#             ],
#             "scored": True,
#             "setup": "",
#             "teardown": "",
#             "type": "doctest"
#         }
#     ]
# }

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/q4.py
# OK_FORMAT = True
# 
# test = {
#     "name": "q4",
#     "points": 3,
#     "suites": [
#         {
#             "cases": [
#                 {
#                     "code": r"""
# >>> # Teste 1: Flag criada
# >>> bool('price_was_missing' in df.columns)
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 },
#                 {
#                     "code": r"""
# >>> # Teste 2: Flag é inteira
# >>> bool(df['price_was_missing'].dtype in ['int64', 'int32', 'uint8'])
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 }
#             ],
#             "scored": True,
#             "setup": "",
#             "teardown": "",
#             "type": "doctest"
#         }
#     ]
# }

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/q5.py
# OK_FORMAT = True
# 
# test = {
#     "name": "q5",
#     "points": 3,
#     "suites": [
#         {
#             "cases": [
#                 {
#                     "code": r"""
# >>> # Teste 1: Sem missing em price
# >>> bool(df_clean['price'].isnull().sum() == 0)
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 },
#                 {
#                     "code": r"""
# >>> # Teste 2: Menos missing que original
# >>> bool(df_clean.isnull().sum().sum() < df_original.isnull().sum().sum())
# True
# """,
#                     "hidden": False,
#                     "locked": False
#                 }
#             ],
#             "scored": True,
#             "setup": "",
#             "teardown": "",
#             "type": "doctest"
#         }
#     ]
# }

import otter
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

grader = otter.Notebook()

print("✓ Otter Grader carregado")
print("✓ Pandas importado")
print(f"✓ Versão Pandas: {pd.__version__}")

"""## Carregar Dados

Vamos trabalhar com um dataset de pedidos de e-commerce que contém diversos problemas de qualidade de dados.
"""

# Carregar o dataset
# Se estiver no Colab, faça upload do arquivo primeiro
try:
    df = pd.read_csv('ecommerce_orders_dirty.csv')
    print("✓ Dataset carregado com sucesso!")
except FileNotFoundError:
    print("⚠ Arquivo não encontrado. Faça upload do 'ecommerce_orders_dirty.csv'")
    print("\nPara fazer upload no Colab:")
    print("from google.colab import files")
    print("uploaded = files.upload()")
    print("df = pd.read_csv('ecommerce_orders_dirty.csv')")

# Converter order_date para datetime
df['order_date'] = pd.to_datetime(df['order_date'])

# Criar cópia original
df_original = df.copy()

print(f"\nShape: {df.shape}")
print(f"\nPrimeiras linhas:")
display(df.head())

print(f"\nTipos de dados:")
print(df.dtypes)

"""# Exercício 1: Criar Relatório de Missing Values (7 min)

## Descrição
Crie uma função que gera um relatório detalhado de valores faltantes no dataset.

O relatório deve incluir:
- Nome da coluna
- Quantidade de valores faltantes
- Percentual de valores faltantes
- Tipo de dado da coluna

O relatório deve:
- Incluir apenas colunas com missing > 0
- Estar ordenado por percentual decrescente

## Exemplo
```python
generate_missing_report(df)
#        Column  Missing_Count  Missing_Pct     Dtype
# 0       price            126        15.37   float64
# 1    quantity             81         9.88    object
# ...
```

## Dicas
- Use `df.isnull().sum()` para contar missing
- Calcule percentual: `(missing_count / len(df)) * 100`
- Crie DataFrame com `pd.DataFrame({...})`
- Filtre com: `report[report['Missing_Count'] > 0]`
- Ordene com: `report.sort_values('Missing_Pct', ascending=False)`
"""

def generate_missing_report(df):
    """
    Gera relatório de valores faltantes.

    Parameters:
    -----------
    df : DataFrame
        Dataset a analisar

    Returns:
    --------
    DataFrame com colunas: Column, Missing_Count, Missing_Pct, Dtype
    """
    # === SEU CÓDIGO AQUI ===


    # === FIM DO SEU CÓDIGO ===

# Testar sua função
print("=== TESTE Q1 ===")
missing_report = generate_missing_report(df)
print("\nRelatório de Missing Values:")
display(missing_report)

print(f"\nTotal de colunas com missing: {len(missing_report)}")
print(f"Coluna com mais missing: {missing_report.iloc[0]['Column']} ({missing_report.iloc[0]['Missing_Pct']:.2f}%)")

grader.check("q1")

"""# Exercício 2: Limpeza de Strings (7 min)

## Descrição
Limpe as colunas categóricas do dataset removendo espaços extras e padronizando a capitalização.

Para as colunas 'status', 'payment_method', 'region' e 'category':
1. Remova espaços no início e fim (`.str.strip()`)
2. Converta tudo para minúsculo (`.str.lower()`)

## Exemplo
```python
# Antes:
'DELIVERED', ' Delivered', 'delivered ', ' delivered '

# Depois:
'delivered', 'delivered', 'delivered', 'delivered'
```

## Dicas
- Use um loop for para processar cada coluna
- Aplique as transformações em ordem: strip() depois lower()
- Transformações de string: `df[col].str.strip().str.lower()`
"""

# === SEU CÓDIGO AQUI ===


# === FIM DO SEU CÓDIGO ===

# Verificar resultado
print("=== TESTE Q2 ===")
print("\nValores únicos em 'status':")
print(df['status'].value_counts())

print("\nVerificando espaços extras...")
has_spaces = df['status'].str.contains(' ').sum()
print(f"Registros com espaços: {has_spaces}")

print("\nVerificando maiúsculas...")
all_lower = df['status'].str.islower().all()
print(f"Todos em minúsculo: {all_lower}")

grader.check("q2")

"""# Exercício 3: Converter Tipos e Tratar Valores Inválidos (7 min)

## Descrição
A coluna 'quantity' está como tipo 'object' porque contém valores inválidos como 'Unknown', '???', 'N/A'.

Também há valores inválidos em 'price' (negativos ou muito altos) e 'customer_id' (negativos).

Tarefas:
1. Converter 'quantity' para numérico usando `pd.to_numeric()` com `errors='coerce'`
2. Marcar valores inválidos em 'price' como NaN:
   - Preços negativos (< 0)
   - Preços muito altos (> 50000)
3. Marcar 'customer_id' negativos como NaN

## Exemplo
```python
# Antes:
quantity: ['2', '3', 'Unknown', '1', '???']
price: [100, -50, 250, 1000000, 75]

# Depois:
quantity: [2.0, 3.0, NaN, 1.0, NaN]
price: [100, NaN, 250, NaN, 75]
```

## Dicas
- `pd.to_numeric(df['col'], errors='coerce')` converte e transforma inválidos em NaN
- Use `~df['col'].between(min, max)` para identificar valores fora do range
- Substitua por NaN: `df.loc[mask, 'col'] = np.nan`
"""

# === SEU CÓDIGO AQUI ===


# === FIM DO SEU CÓDIGO ===

# Verificar resultado
print("=== TESTE Q3 ===")
print(f"\nTipo de 'quantity': {df['quantity'].dtype}")
print(f"É numérico: {pd.api.types.is_numeric_dtype(df['quantity'])}")

print(f"\nRange de 'price':")
print(f"  Mínimo: {df['price'].min():.2f}")
print(f"  Máximo: {df['price'].max():.2f}")
print(f"  Valores negativos: {(df['price'] < 0).sum()}")

print(f"\nRange de 'customer_id':")
print(f"  Mínimo: {df['customer_id'].min()}")
print(f"  Valores negativos: {(df['customer_id'] < 0).sum()}")

grader.check("q3")

"""# Exercício 4: Criar Flags de Imputação (7 min)

## Descrição
Antes de imputar valores faltantes, é boa prática criar flags (colunas indicadoras) que registram quais valores estavam faltando.

Crie flags para as colunas:
- 'price'
- 'quantity'
- 'category'

Para cada coluna X, crie uma nova coluna chamada 'X_was_missing' que contém:
- 1 se o valor estava faltando
- 0 se o valor estava presente

## Exemplo
```python
# Se price = [100, NaN, 250, NaN, 75]
# Então price_was_missing = [0, 1, 0, 1, 0]
```

## Dicas
- Use `df[col].isnull()` para detectar NaN
- Use `.astype(int)` para converter True/False em 1/0
- Crie nova coluna: `df['nova_col'] = ...`
"""

# === SEU CÓDIGO AQUI ===



# === FIM DO SEU CÓDIGO ===

# Verificar resultado
print("=== TESTE Q4 ===")
print("\nFlags criadas:")
flag_cols = [col for col in df.columns if '_was_missing' in col]
for col in flag_cols:
    print(f"  {col}: {df[col].sum()} valores marcados")

print("\nExemplo de dados com flags:")
display(df[['price', 'price_was_missing', 'quantity', 'quantity_was_missing']].head(10))

grader.check("q4")

"""# Exercício 5: Imputação e Pipeline Final (7 min)

## Descrição
Complete o pipeline de limpeza implementando as seguintes imputações:

1. **price**: Imputar com mediana por 'category' (depois mediana global para restantes)
2. **quantity**: Imputar com mediana global
3. **category**: Imputar com a moda (valor mais frequente)
4. **payment_method**: Imputar com a moda
5. **customer_id**: Imputar com valor especial (-1) para indicar "desconhecido"
6. Remover duplicatas

## Exemplo de Imputação por Grupo
```python
df['price'] = df.groupby('category')['price'].transform(
    lambda x: x.fillna(x.median())
)
```

## Dicas
- Use `groupby().transform()` para imputação por grupo
- Use `fillna()` para imputação simples
- Moda: `df[col].mode()[0]` (pegue o primeiro valor)
- Duplicatas: `df.drop_duplicates()`
"""

# Criar função de pipeline completo
def clean_ecommerce_pipeline(df_raw):
    """
    Pipeline completo de limpeza.

    Parameters:
    -----------
    df_raw : DataFrame
        Dataset bruto

    Returns:
    --------
    DataFrame limpo
    """
    # === SEU CÓDIGO AQUI ===



    # === FIM DO SEU CÓDIGO ===

# Executar pipeline
print("=== TESTE Q5 ===")
df_clean = clean_ecommerce_pipeline(df)

print("\n" + "=" * 60)
print("COMPARAÇÃO ANTES vs DEPOIS")
print("=" * 60)

print(f"\nMissing values:")
print(f"  Antes: {df_original.isnull().sum().sum()}")
print(f"  Depois: {df_clean.isnull().sum().sum()}")

print(f"\nRegistros:")
print(f"  Antes: {len(df_original):,}")
print(f"  Depois: {len(df_clean):,}")

print("\nMissing por coluna DEPOIS:")
print(df_clean.isnull().sum())

grader.check("q5")

"""## Validação Final e Análise"""

# Checklist final
print("=" * 60)
print("CHECKLIST FINAL")
print("=" * 60)

checks = [
    ("Sem missing em price", df_clean['price'].isnull().sum() == 0),
    ("Sem missing em quantity", df_clean['quantity'].isnull().sum() == 0),
    ("Sem missing em category", df_clean['category'].isnull().sum() == 0),
    ("quantity é numérico", pd.api.types.is_numeric_dtype(df_clean['quantity'])),
    ("Strings limpas", not df_clean['status'].str.contains(' ').any()),
    ("Flags criadas", 'price_was_missing' in df_clean.columns),
    ("Sem valores negativos em price", (df_clean['price'] >= 0).all()),
]

all_passed = True
for check_name, check_result in checks:
    status = "✓" if check_result else "✗"
    print(f"{status} {check_name}")
    if not check_result:
        all_passed = False

if all_passed:
    print("\n" + "=" * 60)
    print("DATASET LIMPO COM SUCESSO!")
    print("=" * 60)
else:
    print("\n" + "=" * 60)
    print("Algumas verificações falharam. Revise o processo.")
    print("=" * 60)

# Análise rápida dos dados limpos
print("=" * 60)
print("ANÁLISE DOS DADOS LIMPOS")
print("=" * 60)

print("\n Estatísticas Descritivas:")
display(df_clean[['price', 'quantity']].describe())

print("\n Top 5 Produtos Mais Vendidos:")
display(df_clean['product'].value_counts().head())

print("\n Faturamento Total por Categoria:")
df_clean['revenue'] = df_clean['price'] * df_clean['quantity']
revenue_by_category = df_clean.groupby('category')['revenue'].sum().sort_values(ascending=False)
display(revenue_by_category)

print("\n Vendas por Região:")
display(df_clean['region'].value_counts())

print("\n Status dos Pedidos:")
display(df_clean['status'].value_counts())

# Executar todos os testes
print("=" * 60)
print("EXECUTANDO TODOS OS TESTES")
print("=" * 60)
grader.check_all()

"""## Conclusão

Parabéns! Você completou o exercício de limpeza de dados.

### O que você praticou:
1. **Diagnóstico**: Criar relatórios de missing values
2. **Limpeza de Strings**: Remover espaços e padronizar capitalização
3. **Conversão de Tipos**: Usar pd.to_numeric() e tratar valores inválidos
4. **Flags de Imputação**: Preservar informação sobre valores faltantes
5. **Imputação**: Aplicar estratégias apropriadas por grupo e globalmente
6. **Pipeline Completo**: Organizar todo o processo de forma reproduzível

### Conceitos-chave:
- ✓ Dados sujos são a norma, não a exceção
- ✓ Sempre preserve os dados originais
- ✓ Documente suas decisões
- ✓ Crie flags antes de imputar
- ✓ Valide os resultados sistematicamente

Continue praticando com diferentes datasets!
"""