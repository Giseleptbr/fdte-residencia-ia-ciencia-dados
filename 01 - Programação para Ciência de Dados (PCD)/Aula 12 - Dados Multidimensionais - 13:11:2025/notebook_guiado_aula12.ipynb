{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJh5wJhvLF_X"
      },
      "source": [
        "# Aula 12 - Prática Guiada em Sala\n",
        "**Curso:** Programação para Ciência de Dados  \n",
        "**Tópico:** Dados Multidimensionais (Tensores 3D+)  \n",
        "**Data:** 13 de Novembro 2025  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos da Prática\n",
        "\n",
        "Nesta sessão prática, você irá:\n",
        "\n",
        "1. Manipular tensores 3D e 4D (arrays multidimensionais)\n",
        "2. Dominar o parâmetro `axis` em operações de agregação\n",
        "3. Aplicar indexação avançada (fancy e boolean)\n",
        "4. Utilizar broadcasting eficientemente\n",
        "5. Normalizar dados multidimensionais\n",
        "6. Trabalhar com diferentes tipos de dados 3D+\n",
        "7. Construir pipeline completo de processamento\n",
        "8. Otimizar código para performance\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset: MNIST Digits\n",
        "\n",
        "Utilizaremos o dataset **MNIST** (Modified National Institute of Standards and Technology):\n",
        "- 1797 imagens de dígitos manuscritos (0-9)\n",
        "- Formato: 8×8 pixels em grayscale\n",
        "- Shape: (1797, 8, 8) - tensor 3D\n",
        "- Valores: 0-16 (intensidade de pixels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMeCcJDyLF_Y"
      },
      "outputs": [],
      "source": [
        "# === CONFIGURAÇÃO INICIAL ===\n",
        "\n",
        "!pip install --upgrade pip --quiet\n",
        "!pip cache purge\n",
        "!pip install --upgrade otter-grader --quiet\n",
        "!mkdir -p tests\n",
        "\n",
        "print(\"Configuração concluída!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRcycl1ULF_Y"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p1.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p1\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Retorna dicionário\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(100, 8, 8)\n",
        ">>> resultado = analise_shape(arr)\n",
        ">>> isinstance(resultado, dict)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Chaves corretas\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(10, 5, 3)\n",
        ">>> resultado = analise_shape(arr)\n",
        ">>> set(resultado.keys()) == {'ndim', 'shape', 'size', 'dtype'}\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 3: Valores corretos\n",
        ">>> import numpy as np\n",
        ">>> arr = np.ones((5, 4, 3))\n",
        ">>> resultado = analise_shape(arr)\n",
        ">>> resultado['ndim'] == 3 and resultado['size'] == 60\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLviOjbgLF_Z"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p2.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p2\",\n",
        "    \"points\": 1.5,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Shape correto axis=0\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(10, 5, 3)\n",
        ">>> resultado = agregar_axis(arr, axis=0, operacao='mean')\n",
        ">>> resultado.shape == (5, 3)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Operação correta\n",
        ">>> import numpy as np\n",
        ">>> arr = np.ones((5, 4, 3))\n",
        ">>> resultado = agregar_axis(arr, axis=1, operacao='sum')\n",
        ">>> np.allclose(resultado, np.ones((5, 3)) * 4)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlUV7PILLF_Z"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p3.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p3\",\n",
        "    \"points\": 1.5,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Shape preservado\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(50, 10, 10)\n",
        ">>> resultado = selecionar_indices(arr, [0, 5, 10], [2, 3, 4], [1, 2, 3])\n",
        ">>> resultado.shape == (3,)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Boolean indexing correto\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(100, 8, 8)\n",
        ">>> resultado = filtrar_por_media(arr, threshold=0.5)\n",
        ">>> resultado.ndim == 3\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTyQ_sZULF_Z"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p4.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p4\",\n",
        "    \"points\": 1.5,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Normalização global\n",
        ">>> import numpy as np\n",
        ">>> arr = np.array([[[0, 10], [5, 15]]])\n",
        ">>> resultado = normalizar_tensor(arr, metodo='global')\n",
        ">>> bool(np.isclose(resultado.min(), 0) and np.isclose(resultado.max(), 1))\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Shape preservado\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(20, 8, 8)\n",
        ">>> resultado = normalizar_tensor(arr, metodo='por_amostra')\n",
        ">>> resultado.shape == arr.shape\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tjqvDcjLF_b"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p5.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p5\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Broadcasting funciona\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(10, 5, 3)\n",
        ">>> resultado = aplicar_broadcasting(arr, operacao='subtrair_media')\n",
        ">>> resultado.shape == arr.shape\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Média próxima de zero\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(50, 10, 10)\n",
        ">>> resultado = aplicar_broadcasting(arr, operacao='subtrair_media')\n",
        ">>> bool(np.abs(resultado.mean()) < 1e-10)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R2RXvBULF_b"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p6.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p6\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Retorna dicionário\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(100, 5, 3)\n",
        ">>> resultado = analisar_series_temporal(arr)\n",
        ">>> isinstance(resultado, dict)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Shapes corretos\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(50, 3, 2)\n",
        ">>> resultado = analisar_series_temporal(arr)\n",
        ">>> resultado['media_temporal'].shape == (3, 2)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLeb0mOPLF_c"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p7.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p7\",\n",
        "    \"points\": 1.5,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Retorna dicionário\n",
        ">>> import numpy as np\n",
        ">>> from sklearn.datasets import load_digits\n",
        ">>> digits = load_digits()\n",
        ">>> X, y = digits.images, digits.target\n",
        ">>> resultado = pipeline_mnist(X, y, digitos=[0, 1, 2])\n",
        ">>> isinstance(resultado, dict)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Imagens médias shape correto\n",
        ">>> import numpy as np\n",
        ">>> from sklearn.datasets import load_digits\n",
        ">>> digits = load_digits()\n",
        ">>> X, y = digits.images, digits.target\n",
        ">>> resultado = pipeline_mnist(X, y, digitos=[0, 1])\n",
        ">>> resultado['imagens_medias'].shape == (2, 8, 8)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OadmZqMkLF_c"
      },
      "outputs": [],
      "source": [
        "%%writefile tests/p8.py\n",
        "OK_FORMAT = True\n",
        "\n",
        "test = {\n",
        "    \"name\": \"p8\",\n",
        "    \"points\": 1,\n",
        "    \"suites\": [\n",
        "        {\n",
        "            \"cases\": [\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 1: Versão vetorizada mais rápida\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(1000, 10, 10)\n",
        ">>> tempo_loop, tempo_vec = comparar_performance(arr)\n",
        ">>> tempo_vec < tempo_loop\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                },\n",
        "                {\n",
        "                    \"code\": r\"\"\"\n",
        ">>> # Teste 2: Resultados idênticos\n",
        ">>> import numpy as np\n",
        ">>> arr = np.random.rand(50, 5, 5)\n",
        ">>> resultado_loop = processar_com_loop(arr)\n",
        ">>> resultado_vec = processar_vetorizado(arr)\n",
        ">>> np.allclose(resultado_loop, resultado_vec)\n",
        "True\n",
        "\"\"\",\n",
        "                    \"hidden\": False,\n",
        "                    \"locked\": False\n",
        "                }\n",
        "            ],\n",
        "            \"scored\": True,\n",
        "            \"setup\": \"\",\n",
        "            \"teardown\": \"\",\n",
        "            \"type\": \"doctest\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wmh79UFLF_c"
      },
      "outputs": [],
      "source": [
        "# === CARREGAR OTTER GRADER ===\n",
        "\n",
        "import otter\n",
        "grader = otter.Notebook()\n",
        "\n",
        "print(\"Otter Grader carregado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxrH6p16LF_c"
      },
      "outputs": [],
      "source": [
        "# === IMPORTAR BIBLIOTECAS ===\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "import time\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Seed para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Bibliotecas importadas!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "319wVpOoLF_c"
      },
      "outputs": [],
      "source": [
        "# === CARREGAR DATASET MNIST ===\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.images  # (1797, 8, 8)\n",
        "y = digits.target  # (1797,)\n",
        "\n",
        "print(\"=== DATASET MNIST CARREGADO ===\")\n",
        "print(f\"Shape das imagens (X): {X.shape}\")\n",
        "print(f\"Shape dos labels (y): {y.shape}\")\n",
        "print(f\"Número de classes: {len(np.unique(y))}\")\n",
        "print(f\"Range de valores: [{X.min()}, {X.max()}]\")\n",
        "print(f\"Dtype: {X.dtype}\")\n",
        "\n",
        "# Visualizar algumas imagens\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i in range(10):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    ax.imshow(X[i], cmap='gray')\n",
        "    ax.set_title(f'Label: {y[i]}')\n",
        "    ax.axis('off')\n",
        "plt.suptitle('Primeiras 10 Imagens do MNIST', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDataset pronto para uso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewMdMz3kLF_d"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 1: Análise de Shape\n",
        "\n",
        "## Objetivo\n",
        "Entender e analisar as propriedades básicas de tensores multidimensionais.\n",
        "\n",
        "## Tarefa\n",
        "Implemente a função `analise_shape()` que recebe um tensor e retorna um dicionário com:\n",
        "- `'ndim'`: número de dimensões\n",
        "- `'shape'`: tupla com tamanho de cada dimensão\n",
        "- `'size'`: total de elementos\n",
        "- `'dtype'`: tipo de dados\n",
        "\n",
        "## Dicas\n",
        "```python\n",
        "arr.ndim     # Número de dimensões\n",
        "arr.shape    # Shape (tupla)\n",
        "arr.size     # Total de elementos\n",
        "arr.dtype    # Tipo de dados\n",
        "```\n",
        "\n",
        "## Retorno Esperado\n",
        "Dicionário com 4 chaves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7KwyTbOLF_d"
      },
      "outputs": [],
      "source": [
        "def analise_shape(arr):\n",
        "    \"\"\"\n",
        "    Analisa propriedades básicas de um tensor.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor de qualquer dimensionalidade\n",
        "\n",
        "    Returns:\n",
        "        dict: Dicionário com propriedades do tensor\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    info = {\n",
        "        'ndim': arr.ndim,\n",
        "        'shape': arr.shape,\n",
        "        'size': arr.size,\n",
        "        'dtype': arr.dtype\n",
        "    }\n",
        "\n",
        "    return info\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKHa97jHLF_d"
      },
      "outputs": [],
      "source": [
        "# Testar função\n",
        "print(\"=== ANÁLISE DO MNIST ===\")\n",
        "info_mnist = analise_shape(X)\n",
        "\n",
        "for chave, valor in info_mnist.items():\n",
        "    print(f\"{chave}: {valor}\")\n",
        "\n",
        "# Interpretar dimensões\n",
        "print(\"\\n=== INTERPRETAÇÃO ===\")\n",
        "print(f\"Temos {info_mnist['shape'][0]} imagens\")\n",
        "print(f\"Cada imagem tem {info_mnist['shape'][1]}x{info_mnist['shape'][2]} pixels\")\n",
        "print(f\"Total de pixels no dataset: {info_mnist['size']}\")\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m464L-bLF_d"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 2: Operações com Axis\n",
        "\n",
        "## Objetivo\n",
        "Dominar o uso do parâmetro `axis` em operações de agregação.\n",
        "\n",
        "## Tarefa\n",
        "Implemente a função `agregar_axis()` que:\n",
        "1. Recebe um tensor 3D, um `axis`, e uma `operacao` ('mean', 'sum', 'max', 'min')\n",
        "2. Aplica a operação no eixo especificado\n",
        "3. Retorna o resultado agregado\n",
        "\n",
        "## Conceito Importante\n",
        "- `axis=0`: agrega ao longo da primeira dimensão (dimensão desaparece)\n",
        "- `axis=1`: agrega ao longo da segunda dimensão\n",
        "- `axis=2`: agrega ao longo da terceira dimensão\n",
        "\n",
        "## Exemplo\n",
        "```python\n",
        "arr = np.ones((10, 5, 3))\n",
        "arr.mean(axis=0)  # (5, 3) - média ao longo das 10 amostras\n",
        "arr.sum(axis=1)   # (10, 3) - soma ao longo das 5 features\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CfM-YpTLF_d"
      },
      "outputs": [],
      "source": [
        "def agregar_axis(arr, axis, operacao='mean'):\n",
        "    \"\"\"\n",
        "    Agrega tensor ao longo de um eixo específico.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D\n",
        "        axis (int): Eixo para agregar (0, 1, ou 2)\n",
        "        operacao (str): Operação ('mean', 'sum', 'max', 'min')\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tensor agregado\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    if operacao == 'mean':\n",
        "        resultado = arr.mean(axis=axis)\n",
        "    elif operacao == 'sum':\n",
        "        resultado = arr.sum(axis=axis)\n",
        "    elif operacao == 'max':\n",
        "        resultado = arr.max(axis=axis)\n",
        "    elif operacao == 'min':\n",
        "        resultado = arr.min(axis=axis)\n",
        "    else:\n",
        "        raise ValueError(f\"Operação '{operacao}' não suportada\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iZeuNiKLF_f"
      },
      "outputs": [],
      "source": [
        "# Testar com MNIST\n",
        "print(\"=== AGREGAÇÕES NO MNIST ===\")\n",
        "print(f\"Shape original: {X.shape}\\n\")\n",
        "\n",
        "# Agregar ao longo de axis=0 (média de todas as imagens)\n",
        "media_todas_imagens = agregar_axis(X, axis=0, operacao='mean')\n",
        "print(f\"Media axis=0: {media_todas_imagens.shape}\")\n",
        "print(\"  → Média de cada posição de pixel através de todas as imagens\\n\")\n",
        "\n",
        "# Agregar ao longo de axis=1 (média por linha)\n",
        "media_linhas = agregar_axis(X, axis=1, operacao='mean')\n",
        "print(f\"Media axis=1: {media_linhas.shape}\")\n",
        "print(\"  → Média de cada linha de cada imagem\\n\")\n",
        "\n",
        "# Agregar ao longo de axis=2 (média por coluna)\n",
        "media_colunas = agregar_axis(X, axis=2, operacao='mean')\n",
        "print(f\"Media axis=2: {media_colunas.shape}\")\n",
        "print(\"  → Média de cada coluna de cada imagem\\n\")\n",
        "\n",
        "# Visualizar média de todas as imagens\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(media_todas_imagens, cmap='gray')\n",
        "plt.title('Imagem Média de Todo o Dataset', fontsize=14)\n",
        "plt.colorbar(label='Intensidade Média')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A0XfJAtLF_f"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 3: Indexação Avançada\n",
        "\n",
        "## Objetivo\n",
        "Aplicar fancy indexing e boolean indexing em tensores 3D.\n",
        "\n",
        "## Tarefa\n",
        "Implemente duas funções:\n",
        "\n",
        "### 3.1: `selecionar_indices()` - Fancy Indexing\n",
        "- Recebe tensor 3D e três listas de índices (para cada dimensão)\n",
        "- Retorna elementos específicos usando fancy indexing\n",
        "\n",
        "### 3.2: `filtrar_por_media()` - Boolean Indexing\n",
        "- Recebe tensor 3D e um threshold\n",
        "- Retorna apenas amostras cuja média espacial (axis=(1,2)) é maior que threshold\n",
        "\n",
        "## Conceitos\n",
        "```python\n",
        "# Fancy indexing\n",
        "arr[[1, 3, 5]]  # Seleciona linhas 1, 3, 5\n",
        "\n",
        "# Boolean indexing\n",
        "mask = arr.mean(axis=1) > 10\n",
        "arr[mask]  # Seleciona onde máscara é True\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL_d3-yFLF_f"
      },
      "outputs": [],
      "source": [
        "def selecionar_indices(arr, indices_0, indices_1, indices_2):\n",
        "    \"\"\"\n",
        "    Seleciona elementos específicos usando fancy indexing.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D\n",
        "        indices_0 (list): Índices para dimensão 0\n",
        "        indices_1 (list): Índices para dimensão 1\n",
        "        indices_2 (list): Índices para dimensão 2\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Elementos selecionados\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    resultado = arr[indices_0, indices_1, indices_2]\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ===\n",
        "\n",
        "\n",
        "def filtrar_por_media(arr, threshold):\n",
        "    \"\"\"\n",
        "    Filtra amostras por média espacial usando boolean indexing.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (amostras, altura, largura)\n",
        "        threshold (float): Valor de corte\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Amostras filtradas\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    # Calcular média espacial de cada amostra\n",
        "    medias = arr.mean(axis=(1, 2))\n",
        "\n",
        "    # Criar máscara booleana\n",
        "    mask = medias > threshold\n",
        "\n",
        "    # Aplicar máscara\n",
        "    resultado = arr[mask]\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testar fancy indexing\n",
        "print(\"=== FANCY INDEXING ===\")\n",
        "indices_imgs = [0, 10, 100]\n",
        "indices_rows = [3, 4, 5]\n",
        "indices_cols = [2, 3, 4]\n",
        "\n",
        "pixels_selecionados = selecionar_indices(X, indices_imgs, indices_rows, indices_cols)\n",
        "print(f\"Shape resultante: {pixels_selecionados.shape}\")\n",
        "print(f\"Valores: {pixels_selecionados}\")\n",
        "print(\"  → Selecionou pixels específicos de imagens específicas\\n\")\n",
        "\n",
        "# Testar boolean indexing\n",
        "print(\"=== BOOLEAN INDEXING ===\")\n",
        "threshold = 6.5\n",
        "imagens_claras = filtrar_por_media(X, threshold)\n",
        "\n",
        "print(f\"Total de imagens originais: {X.shape[0]}\")\n",
        "print(f\"Threshold: {threshold}\")\n",
        "print(f\"Imagens acima do threshold: {imagens_claras.shape[0]}\")\n",
        "print(f\"Percentual filtrado: {100 * imagens_claras.shape[0] / X.shape[0]:.1f}%\\n\")\n",
        "\n",
        "# Visualizar comparação\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "axes[0, 0].set_ylabel('Originais', fontsize=12, rotation=0, labelpad=40)\n",
        "axes[1, 0].set_ylabel('Filtradas\\n(claras)', fontsize=12, rotation=0, labelpad=40)\n",
        "\n",
        "# Determine quantas imagens podemos exibir (mínimo entre 5 e disponíveis)\n",
        "num_to_display = min(5, imagens_claras.shape[0])\n",
        "\n",
        "for i in range(5):\n",
        "    # Primeira linha: sempre mostra originais\n",
        "    axes[0, i].imshow(X[i], cmap='gray')\n",
        "    axes[0, i].set_title(f'Média: {X[i].mean():.1f}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    # Segunda linha: só mostra se houver imagens filtradas suficientes\n",
        "    if i < num_to_display:\n",
        "        axes[1, i].imshow(imagens_claras[i], cmap='gray')\n",
        "        axes[1, i].set_title(f'Média: {imagens_claras[i].mean():.1f}')\n",
        "    else:\n",
        "        # Exibe placeholder para slots vazios\n",
        "        axes[1, i].text(0.5, 0.5, 'N/A',\n",
        "                       ha='center', va='center',\n",
        "                       transform=axes[1, i].transAxes,\n",
        "                       fontsize=14, color='red')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.suptitle(f'Comparação: Originais vs Filtradas (threshold={threshold})', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p3\")"
      ],
      "metadata": {
        "id": "oPwXj83yMMcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfcyHuSLF_f"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 4: Normalização de Tensores\n",
        "\n",
        "## Objetivo\n",
        "Implementar diferentes estratégias de normalização em tensores 3D.\n",
        "\n",
        "## Tarefa\n",
        "Implemente a função `normalizar_tensor()` com três métodos:\n",
        "\n",
        "### 1. Normalização Global\n",
        "- Normaliza todo o tensor para [0, 1]\n",
        "- Fórmula: `(arr - min) / (max - min)`\n",
        "\n",
        "### 2. Normalização Por Amostra\n",
        "- Normaliza cada amostra independentemente\n",
        "- Usa broadcasting com `keepdims=True`\n",
        "\n",
        "### 3. Padronização Global\n",
        "- Z-score: `(arr - mean) / std`\n",
        "\n",
        "## Conceitos de Broadcasting\n",
        "```python\n",
        "# keepdims preserva dimensões para broadcasting\n",
        "means = arr.mean(axis=(1,2), keepdims=True)  # (n, 1, 1)\n",
        "normalized = arr / means  # Broadcasting funciona!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pid0S3w-LF_f"
      },
      "outputs": [],
      "source": [
        "def normalizar_tensor(arr, metodo='global'):\n",
        "    \"\"\"\n",
        "    Normaliza tensor 3D usando diferentes estratégias.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (amostras, altura, largura)\n",
        "        metodo (str): 'global', 'por_amostra', ou 'padronizar'\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tensor normalizado\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    if metodo == 'global':\n",
        "        # Normalização global: min-max para [0, 1]\n",
        "        min_val = arr.min()\n",
        "        max_val = arr.max()\n",
        "        resultado = (arr - min_val) / (max_val - min_val)\n",
        "\n",
        "    elif metodo == 'por_amostra':\n",
        "        # Normalização por amostra (broadcasting com keepdims)\n",
        "        min_vals = arr.min(axis=(1, 2), keepdims=True)  # (n, 1, 1)\n",
        "        max_vals = arr.max(axis=(1, 2), keepdims=True)\n",
        "        resultado = (arr - min_vals) / (max_vals - min_vals + 1e-10)\n",
        "\n",
        "    elif metodo == 'padronizar':\n",
        "        # Padronização global (z-score)\n",
        "        mean_val = arr.mean()\n",
        "        std_val = arr.std()\n",
        "        resultado = (arr - mean_val) / std_val\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Método '{metodo}' não suportado\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCm-392ILF_f"
      },
      "outputs": [],
      "source": [
        "# Testar diferentes normalizações\n",
        "X_subset = X[:20].copy()\n",
        "\n",
        "print(\"=== COMPARAÇÃO DE NORMALIZAÇÕES ===\")\n",
        "print(f\"\\nOriginal:\")\n",
        "print(f\"  Range: [{X_subset.min():.2f}, {X_subset.max():.2f}]\")\n",
        "print(f\"  Mean: {X_subset.mean():.2f}, Std: {X_subset.std():.2f}\")\n",
        "\n",
        "# Normalização global\n",
        "X_norm_global = normalizar_tensor(X_subset, metodo='global')\n",
        "print(f\"\\nNormalização Global:\")\n",
        "print(f\"  Range: [{X_norm_global.min():.2f}, {X_norm_global.max():.2f}]\")\n",
        "print(f\"  Mean: {X_norm_global.mean():.2f}, Std: {X_norm_global.std():.2f}\")\n",
        "\n",
        "# Normalização por amostra\n",
        "X_norm_amostra = normalizar_tensor(X_subset, metodo='por_amostra')\n",
        "print(f\"\\nNormalização Por Amostra:\")\n",
        "print(f\"  Range global: [{X_norm_amostra.min():.2f}, {X_norm_amostra.max():.2f}]\")\n",
        "print(f\"  Mean: {X_norm_amostra.mean():.2f}, Std: {X_norm_amostra.std():.2f}\")\n",
        "print(f\"  Cada amostra tem seu próprio min=0 e max=1\")\n",
        "\n",
        "# Padronização\n",
        "X_padronizado = normalizar_tensor(X_subset, metodo='padronizar')\n",
        "print(f\"\\nPadronização (z-score):\")\n",
        "print(f\"  Range: [{X_padronizado.min():.2f}, {X_padronizado.max():.2f}]\")\n",
        "print(f\"  Mean: {X_padronizado.mean():.2e}, Std: {X_padronizado.std():.2f}\")\n",
        "\n",
        "# Visualizar comparação\n",
        "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
        "metodos = [\n",
        "    (X_subset, 'Original'),\n",
        "    (X_norm_global, 'Global'),\n",
        "    (X_norm_amostra, 'Por Amostra'),\n",
        "    (X_padronizado, 'Padronizado')\n",
        "]\n",
        "\n",
        "for row in range(2):\n",
        "    for col, (data, titulo) in enumerate(metodos):\n",
        "        idx = row * 2  # Mostrar imagens 0 e 2\n",
        "        axes[row, col].imshow(data[idx], cmap='gray')\n",
        "        axes[row, col].set_title(f'{titulo}\\n[{data[idx].min():.2f}, {data[idx].max():.2f}]')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "plt.suptitle('Comparação de Métodos de Normalização', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y20bCkILF_g"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 5: Broadcasting Avançado\n",
        "\n",
        "## Objetivo\n",
        "Aplicar broadcasting para operações eficientes em tensores.\n",
        "\n",
        "## Tarefa\n",
        "Implemente a função `aplicar_broadcasting()` que:\n",
        "1. Recebe tensor 3D e uma operação\n",
        "2. Aplica operação usando broadcasting (SEM loops!)\n",
        "\n",
        "### Operações Suportadas:\n",
        "- `'subtrair_media'`: Subtrai média de cada amostra\n",
        "- `'dividir_std'`: Divide pelo desvio padrão de cada amostra\n",
        "- `'centralizar_pixel'`: Subtrai média de cada posição de pixel\n",
        "\n",
        "## Conceito Chave\n",
        "```python\n",
        "# Broadcasting com keepdims\n",
        "means = arr.mean(axis=(1,2), keepdims=True)  # (n, 1, 1)\n",
        "centered = arr - means  # Broadcasting automático!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5dl24t-LF_g"
      },
      "outputs": [],
      "source": [
        "def aplicar_broadcasting(arr, operacao='subtrair_media'):\n",
        "    \"\"\"\n",
        "    Aplica operações usando broadcasting (vetorizado).\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (amostras, altura, largura)\n",
        "        operacao (str): Tipo de operação\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tensor processado\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    if operacao == 'subtrair_media':\n",
        "        # Subtrair média de cada amostra\n",
        "        means = arr.mean(axis=(1, 2), keepdims=True)  # (n, 1, 1)\n",
        "        resultado = arr - means\n",
        "\n",
        "    elif operacao == 'dividir_std':\n",
        "        # Dividir por desvio padrão de cada amostra\n",
        "        stds = arr.std(axis=(1, 2), keepdims=True)  # (n, 1, 1)\n",
        "        resultado = arr / (stds + 1e-10)  # Evitar divisão por zero\n",
        "\n",
        "    elif operacao == 'centralizar_pixel':\n",
        "        # Subtrair média de cada posição de pixel\n",
        "        means = arr.mean(axis=0, keepdims=True)  # (1, h, w)\n",
        "        resultado = arr - means\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Operação '{operacao}' não suportada\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD3xvZ_KLF_g"
      },
      "outputs": [],
      "source": [
        "# Testar broadcasting\n",
        "X_test = X[:50].copy()\n",
        "\n",
        "print(\"=== OPERAÇÕES COM BROADCASTING ===\")\n",
        "print(f\"Shape original: {X_test.shape}\\n\")\n",
        "\n",
        "# Subtrair média\n",
        "X_centered = aplicar_broadcasting(X_test, 'subtrair_media')\n",
        "print(\"Subtrair Média:\")\n",
        "print(f\"  Mean global original: {X_test.mean():.4f}\")\n",
        "print(f\"  Mean global após: {X_centered.mean():.10f}\")\n",
        "print(f\"  ✓ Cada amostra agora tem média ~0\\n\")\n",
        "\n",
        "# Dividir por std\n",
        "X_scaled = aplicar_broadcasting(X_test, 'dividir_std')\n",
        "print(\"Dividir por Std:\")\n",
        "print(f\"  Std médio das amostras: {X_scaled.std(axis=(1,2)).mean():.4f}\")\n",
        "print(f\"  ✓ Escalou valores pelo desvio padrão\\n\")\n",
        "\n",
        "# Centralizar por pixel\n",
        "X_pixel_centered = aplicar_broadcasting(X_test, 'centralizar_pixel')\n",
        "print(\"Centralizar por Pixel:\")\n",
        "print(f\"  Media de cada posição de pixel após: {X_pixel_centered.mean(axis=0).mean():.10f}\")\n",
        "print(f\"  ✓ Cada posição de pixel tem média ~0 através das amostras\\n\")\n",
        "\n",
        "# Visualizar efeito de centralizar\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "operacoes_vis = [\n",
        "    (X_test, 'Original'),\n",
        "    (X_centered, 'Centrado (por amostra)'),\n",
        "    (X_pixel_centered, 'Centrado (por pixel)')\n",
        "]\n",
        "\n",
        "for row in range(2):\n",
        "    for col, (data, titulo) in enumerate(operacoes_vis):\n",
        "        idx = row * 10\n",
        "        axes[row, col].imshow(data[idx], cmap='gray')\n",
        "        axes[row, col].set_title(f'{titulo}\\nMédia: {data[idx].mean():.2f}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "plt.suptitle('Efeitos do Broadcasting em Normalização', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obU8s_zqLF_g"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 6: Análise de Séries Temporais Multivariadas\n",
        "\n",
        "## Objetivo\n",
        "Aplicar conceitos de tensores em dados de séries temporais.\n",
        "\n",
        "## Contexto\n",
        "Séries temporais multivariadas são tensores 3D:\n",
        "- Shape: (tempo, variáveis, locais)\n",
        "- Exemplo: (100 dias, 5 sensores, 3 horários)\n",
        "\n",
        "## Tarefa\n",
        "Implemente `analisar_series_temporal()` que retorna dicionário com:\n",
        "- `'media_temporal'`: média ao longo do tempo (axis=0)\n",
        "- `'media_por_dia'`: média de cada dia (axis=(1,2))\n",
        "- `'variabilidade'`: desvio padrão ao longo do tempo\n",
        "- `'dias_quentes'`: quantidade de dias onde média > threshold\n",
        "\n",
        "## Conceito\n",
        "Mesmas operações do MNIST, mas interpretação diferente!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfmtZ8C1LF_g"
      },
      "outputs": [],
      "source": [
        "def analisar_series_temporal(arr, threshold=22.0):\n",
        "    \"\"\"\n",
        "    Analisa série temporal multivariada.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (tempo, variáveis, locais)\n",
        "        threshold (float): Limite para dias quentes\n",
        "\n",
        "    Returns:\n",
        "        dict: Estatísticas da série\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    # Média temporal (média de cada sensor/horário ao longo do tempo)\n",
        "    media_temporal = arr.mean(axis=0)\n",
        "\n",
        "    # Média por dia (média de todos sensores/horários em cada dia)\n",
        "    media_por_dia = arr.mean(axis=(1, 2))\n",
        "\n",
        "    # Variabilidade temporal (quanto cada sensor varia ao longo do tempo)\n",
        "    variabilidade = arr.std(axis=0)\n",
        "\n",
        "    # Dias quentes (dias onde média está acima do threshold)\n",
        "    dias_quentes = (media_por_dia > threshold).sum()\n",
        "\n",
        "    resultado = {\n",
        "        'media_temporal': media_temporal,\n",
        "        'media_por_dia': media_por_dia,\n",
        "        'variabilidade': variabilidade,\n",
        "        'dias_quentes': dias_quentes\n",
        "    }\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daSnPpQFLF_g"
      },
      "outputs": [],
      "source": [
        "# Criar dados sintéticos de temperatura\n",
        "np.random.seed(42)\n",
        "n_dias, n_sensores, n_horarios = 100, 5, 3\n",
        "\n",
        "# Temperatura base + variação + tendência temporal\n",
        "temp_base = 20\n",
        "temp_data = np.random.randn(n_dias, n_sensores, n_horarios) * 3 + temp_base\n",
        "\n",
        "# Adicionar tendência de aquecimento\n",
        "tendencia = np.linspace(0, 5, n_dias)\n",
        "temp_data += tendencia[:, np.newaxis, np.newaxis]\n",
        "\n",
        "print(\"=== DADOS DE TEMPERATURA ===\")\n",
        "print(f\"Shape: {temp_data.shape}\")\n",
        "print(f\"  {n_dias} dias × {n_sensores} sensores × {n_horarios} horários\")\n",
        "print(f\"Range: [{temp_data.min():.1f}°C, {temp_data.max():.1f}°C]\")\n",
        "print(f\"Média global: {temp_data.mean():.1f}°C\\n\")\n",
        "\n",
        "# Analisar série temporal\n",
        "stats_temp = analisar_series_temporal(temp_data, threshold=22.0)\n",
        "\n",
        "print(\"=== ANÁLISE DA SÉRIE TEMPORAL ===\")\n",
        "print(f\"\\nMédia Temporal (por sensor/horário):\")\n",
        "print(f\"  Shape: {stats_temp['media_temporal'].shape}\")\n",
        "print(f\"  Sensor mais quente: {stats_temp['media_temporal'].max():.1f}°C\")\n",
        "print(f\"  Sensor mais frio: {stats_temp['media_temporal'].min():.1f}°C\")\n",
        "\n",
        "print(f\"\\nMédia Por Dia:\")\n",
        "print(f\"  Shape: {stats_temp['media_por_dia'].shape}\")\n",
        "print(f\"  Dia mais quente: {stats_temp['media_por_dia'].max():.1f}°C\")\n",
        "print(f\"  Dia mais frio: {stats_temp['media_por_dia'].min():.1f}°C\")\n",
        "\n",
        "print(f\"\\nVariabilidade:\")\n",
        "print(f\"  Sensor mais variável: std={stats_temp['variabilidade'].max():.2f}°C\")\n",
        "print(f\"  Sensor mais estável: std={stats_temp['variabilidade'].min():.2f}°C\")\n",
        "\n",
        "print(f\"\\nDias Quentes (>22°C):\")\n",
        "print(f\"  Total: {stats_temp['dias_quentes']} de {n_dias} dias\")\n",
        "print(f\"  Percentual: {100 * stats_temp['dias_quentes'] / n_dias:.1f}%\")\n",
        "\n",
        "# Visualizar série temporal\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Gráfico 1: Temperatura por dia\n",
        "axes[0].plot(stats_temp['media_por_dia'], linewidth=2)\n",
        "axes[0].axhline(22, color='r', linestyle='--', label='Threshold (22°C)')\n",
        "axes[0].set_xlabel('Dia')\n",
        "axes[0].set_ylabel('Temperatura Média (°C)')\n",
        "axes[0].set_title('Evolução da Temperatura Média por Dia')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Heatmap média temporal\n",
        "im = axes[1].imshow(stats_temp['media_temporal'], cmap='RdYlBu_r', aspect='auto')\n",
        "axes[1].set_xlabel('Horário')\n",
        "axes[1].set_ylabel('Sensor')\n",
        "axes[1].set_title('Temperatura Média por Sensor e Horário')\n",
        "axes[1].set_xticks([0, 1, 2])\n",
        "axes[1].set_xticklabels(['Manhã', 'Tarde', 'Noite'])\n",
        "plt.colorbar(im, ax=axes[1], label='Temperatura (°C)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFWjiE1kLF_g"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 7: Pipeline Completo MNIST\n",
        "\n",
        "## Objetivo\n",
        "Construir pipeline end-to-end de processamento de dados multidimensionais.\n",
        "\n",
        "## Tarefa\n",
        "Implemente `pipeline_mnist()` que:\n",
        "1. Filtra apenas dígitos especificados\n",
        "2. Normaliza imagens para [0, 1]\n",
        "3. Calcula imagem média por classe\n",
        "4. Calcula matriz de correlação entre classes\n",
        "5. Retorna dicionário com todos os resultados\n",
        "\n",
        "## Pipeline\n",
        "```\n",
        "Entrada → Filtrar → Normalizar → Agregar → Analisar → Resultados\n",
        "```\n",
        "\n",
        "## Retorno Esperado\n",
        "Dicionário com:\n",
        "- `'n_imagens_por_classe'`: array com contagens\n",
        "- `'imagens_medias'`: tensor (n_classes, 8, 8)\n",
        "- `'correlacao'`: matriz (n_classes, n_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auj-FW8ZLF_g"
      },
      "outputs": [],
      "source": [
        "def pipeline_mnist(X, y, digitos=[0, 1, 2]):\n",
        "    \"\"\"\n",
        "    Pipeline completo de análise do MNIST.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Imagens (n, 8, 8)\n",
        "        y (np.ndarray): Labels (n,)\n",
        "        digitos (list): Dígitos a analisar\n",
        "\n",
        "    Returns:\n",
        "        dict: Resultados da análise\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    # 1. Filtrar dígitos\n",
        "    mask = np.isin(y, digitos)\n",
        "    X_filtrado = X[mask]\n",
        "    y_filtrado = y[mask]\n",
        "\n",
        "    # 2. Normalizar para [0, 1]\n",
        "    X_normalizado = (X_filtrado - X_filtrado.min()) / (X_filtrado.max() - X_filtrado.min())\n",
        "\n",
        "    # 3. Calcular imagem média por classe\n",
        "    n_imagens_por_classe = []\n",
        "    imagens_medias = []\n",
        "\n",
        "    for digito in digitos:\n",
        "        mask_classe = y_filtrado == digito\n",
        "        X_classe = X_normalizado[mask_classe]\n",
        "\n",
        "        n_imagens_por_classe.append(X_classe.shape[0])\n",
        "        imagens_medias.append(X_classe.mean(axis=0))\n",
        "\n",
        "    n_imagens_por_classe = np.array(n_imagens_por_classe)\n",
        "    imagens_medias = np.array(imagens_medias)\n",
        "\n",
        "    # 4. Calcular matriz de correlação entre classes\n",
        "    # Flatten cada imagem média para calcular correlação\n",
        "    imagens_flat = imagens_medias.reshape(len(digitos), -1)\n",
        "    correlacao = np.corrcoef(imagens_flat)\n",
        "\n",
        "    # 5. Montar resultado\n",
        "    resultado = {\n",
        "        'n_imagens_por_classe': n_imagens_por_classe,\n",
        "        'imagens_medias': imagens_medias,\n",
        "        'correlacao': correlacao\n",
        "    }\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aIHKM9aLF_g"
      },
      "outputs": [],
      "source": [
        "# Executar pipeline\n",
        "digitos_analisar = [0, 1, 2, 3, 4]\n",
        "resultados = pipeline_mnist(X, y, digitos=digitos_analisar)\n",
        "\n",
        "print(\"=== RESULTADOS DO PIPELINE ===\")\n",
        "print(f\"\\nDígitos analisados: {digitos_analisar}\")\n",
        "print(f\"\\nImagens por classe:\")\n",
        "for i, digito in enumerate(digitos_analisar):\n",
        "    print(f\"  Dígito {digito}: {resultados['n_imagens_por_classe'][i]} imagens\")\n",
        "\n",
        "print(f\"\\nImagens médias shape: {resultados['imagens_medias'].shape}\")\n",
        "print(f\"Matriz de correlação shape: {resultados['correlacao'].shape}\")\n",
        "\n",
        "# Visualizar imagens médias\n",
        "n_digitos = len(digitos_analisar)\n",
        "fig, axes = plt.subplots(1, n_digitos, figsize=(12, 3))\n",
        "\n",
        "for i, digito in enumerate(digitos_analisar):\n",
        "    axes[i].imshow(resultados['imagens_medias'][i], cmap='gray')\n",
        "    axes[i].set_title(f'Dígito {digito}\\n({resultados[\"n_imagens_por_classe\"][i]} imgs)')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Imagens Médias por Classe', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualizar matriz de correlação\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(resultados['correlacao'], cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.colorbar(im, label='Correlação')\n",
        "plt.xticks(range(n_digitos), digitos_analisar)\n",
        "plt.yticks(range(n_digitos), digitos_analisar)\n",
        "plt.xlabel('Dígito')\n",
        "plt.ylabel('Dígito')\n",
        "plt.title('Matriz de Correlação entre Imagens Médias')\n",
        "\n",
        "# Adicionar valores na matriz\n",
        "for i in range(n_digitos):\n",
        "    for j in range(n_digitos):\n",
        "        text = plt.text(j, i, f'{resultados[\"correlacao\"][i, j]:.2f}',\n",
        "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Insights\n",
        "print(\"\\n=== INSIGHTS ===\")\n",
        "correlacao = resultados['correlacao']\n",
        "np.fill_diagonal(correlacao, 0)  # Ignorar diagonal\n",
        "max_corr_idx = np.unravel_index(correlacao.argmax(), correlacao.shape)\n",
        "print(f\"Dígitos mais similares: {digitos_analisar[max_corr_idx[0]]} e {digitos_analisar[max_corr_idx[1]]}\")\n",
        "print(f\"Correlação: {correlacao[max_corr_idx]:.3f}\")\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynO-jbp3LF_g"
      },
      "source": [
        "---\n",
        "\n",
        "# PRÁTICA 8: Performance - Vetorização vs Loops\n",
        "\n",
        "## Objetivo\n",
        "Demonstrar a importância da vetorização para performance.\n",
        "\n",
        "## Tarefa\n",
        "Implemente três funções que fazem a MESMA coisa:\n",
        "\n",
        "### 1. `processar_com_loop()` - Com loop Python (LENTO)\n",
        "- Centraliza cada imagem subtraindo sua média\n",
        "- Usa loop for\n",
        "\n",
        "### 2. `processar_vetorizado()` - Vetorizado (RÁPIDO)\n",
        "- Mesma operação, mas com broadcasting\n",
        "- SEM loops\n",
        "\n",
        "### 3. `comparar_performance()` - Compara tempos\n",
        "- Executa ambas versões\n",
        "- Retorna tempos e speedup\n",
        "\n",
        "## Conceito\n",
        "Vetorização pode ser 10-100x mais rápida que loops!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAgYai8HLF_g"
      },
      "outputs": [],
      "source": [
        "def processar_com_loop(arr):\n",
        "    \"\"\"\n",
        "    Centraliza imagens usando loop (LENTO).\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (n, h, w)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tensor centralizado\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    resultado = np.zeros_like(arr, dtype=float)\n",
        "\n",
        "    for i in range(arr.shape[0]):\n",
        "        resultado[i] = arr[i] - arr[i].mean()\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ===\n",
        "\n",
        "\n",
        "def processar_vetorizado(arr):\n",
        "    \"\"\"\n",
        "    Centraliza imagens usando broadcasting (RÁPIDO).\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D (n, h, w)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tensor centralizado\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    means = arr.mean(axis=(1, 2), keepdims=True)\n",
        "    resultado = arr - means\n",
        "\n",
        "    return resultado\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ===\n",
        "\n",
        "\n",
        "def comparar_performance(arr):\n",
        "    \"\"\"\n",
        "    Compara performance de loop vs vetorizado.\n",
        "\n",
        "    Args:\n",
        "        arr (np.ndarray): Tensor 3D\n",
        "\n",
        "    Returns:\n",
        "        tuple: (tempo_loop, tempo_vetorizado)\n",
        "    \"\"\"\n",
        "    # === SEU CÓDIGO AQUI ===\n",
        "\n",
        "    # Medir tempo com loop\n",
        "    start = time.time()\n",
        "    _ = processar_com_loop(arr)\n",
        "    tempo_loop = time.time() - start\n",
        "\n",
        "    # Medir tempo vetorizado\n",
        "    start = time.time()\n",
        "    _ = processar_vetorizado(arr)\n",
        "    tempo_vec = time.time() - start\n",
        "\n",
        "    return tempo_loop, tempo_vec\n",
        "\n",
        "    # === FIM DO SEU CÓDIGO ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRElZYycLF_h"
      },
      "outputs": [],
      "source": [
        "# Benchmark com diferentes tamanhos\n",
        "tamanhos = [100, 500, 1000, 1797]\n",
        "resultados_bench = []\n",
        "\n",
        "print(\"=== BENCHMARK: LOOP VS VETORIZADO ===\")\n",
        "print(f\"{'Tamanho':<10} {'Loop (ms)':<12} {'Vetorizado (ms)':<17} {'Speedup'}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for n in tamanhos:\n",
        "    arr_test = X[:n]\n",
        "    tempo_loop, tempo_vec = comparar_performance(arr_test)\n",
        "    speedup = tempo_loop / tempo_vec\n",
        "\n",
        "    print(f\"{n:<10} {tempo_loop*1000:<12.2f} {tempo_vec*1000:<17.2f} {speedup:.1f}x\")\n",
        "    resultados_bench.append((n, tempo_loop*1000, tempo_vec*1000, speedup))\n",
        "\n",
        "# Verificar que resultados são idênticos\n",
        "resultado_loop = processar_com_loop(X[:100])\n",
        "resultado_vec = processar_vetorizado(X[:100])\n",
        "\n",
        "print(\"\\n=== VERIFICAÇÃO DE CORRETUDE ===\")\n",
        "print(f\"Resultados idênticos: {np.allclose(resultado_loop, resultado_vec)}\")\n",
        "print(f\"Diferença máxima: {np.abs(resultado_loop - resultado_vec).max():.10f}\")\n",
        "\n",
        "# Visualizar speedup\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Gráfico 1: Tempos absolutos\n",
        "tamanhos_arr = [r[0] for r in resultados_bench]\n",
        "tempos_loop = [r[1] for r in resultados_bench]\n",
        "tempos_vec = [r[2] for r in resultados_bench]\n",
        "\n",
        "axes[0].plot(tamanhos_arr, tempos_loop, 'o-', label='Loop', linewidth=2, markersize=8)\n",
        "axes[0].plot(tamanhos_arr, tempos_vec, 's-', label='Vetorizado', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Número de Imagens')\n",
        "axes[0].set_ylabel('Tempo (ms)')\n",
        "axes[0].set_title('Tempo de Execução')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Speedup\n",
        "speedups = [r[3] for r in resultados_bench]\n",
        "axes[1].plot(tamanhos_arr, speedups, 'o-', color='green', linewidth=2, markersize=8)\n",
        "axes[1].axhline(1, color='red', linestyle='--', label='Sem ganho')\n",
        "axes[1].set_xlabel('Número de Imagens')\n",
        "axes[1].set_ylabel('Speedup (x vezes)')\n",
        "axes[1].set_title('Ganho de Performance (Vetorizado vs Loop)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== CONCLUSÃO ===\")\n",
        "print(f\"✓ Vetorização é {speedups[-1]:.1f}x mais rápida no dataset completo!\")\n",
        "print(\"✓ Sempre prefira operações vetorizadas a loops Python\")\n",
        "print(\"✓ Broadcasting + NumPy = Performance!\")\n",
        "\n",
        "# Verificar teste\n",
        "grader.check(\"p8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b5AV5qqLF_h"
      },
      "source": [
        "---\n",
        "\n",
        "# 🎓 FINALIZAÇÃO\n",
        "\n",
        "## Verificar Todas as Práticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvMb36sGLF_h"
      },
      "outputs": [],
      "source": [
        "# Executar todos os testes\n",
        "grader.check_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyUB87SOLF_h"
      },
      "source": [
        "---\n",
        "\n",
        "# RESUMO DA PRÁTICA\n",
        "\n",
        "### Fundamentos de Tensores\n",
        "- Análise de shape, ndim, size, dtype\n",
        "- Interpretação de dimensões em diferentes contextos\n",
        "\n",
        "### Operações com Axis\n",
        "- Agregação ao longo de diferentes eixos\n",
        "- `axis=0`, `axis=1`, `axis=2` - cada um tem significado diferente\n",
        "- keepdims para preservar dimensões\n",
        "\n",
        "### Indexação Avançada\n",
        "- Fancy indexing com listas de índices\n",
        "- Boolean indexing com máscaras\n",
        "- Seleção eficiente de subsets\n",
        "\n",
        "### Normalização e Padronização\n",
        "- Normalização global vs por amostra\n",
        "- Broadcasting com keepdims\n",
        "- Trade-offs de cada método\n",
        "\n",
        "### Broadcasting\n",
        "- Operações vetorizadas sem loops\n",
        "- Regras de compatibilidade de shapes\n",
        "- newaxis para adicionar dimensões\n",
        "\n",
        "### Aplicações Práticas\n",
        "- Séries temporais multivariadas\n",
        "- Pipeline completo de análise\n",
        "- Matriz de correlação\n",
        "\n",
        "### Performance\n",
        "- Vetorização 10-100x mais rápida que loops\n",
        "- NumPy otimizado para operações em batch\n",
        "- Sempre prefira broadcasting a loops\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "otter": {
      "OK_FORMAT": true,
      "tests": {
        "p1": {
          "name": "p1",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> import numpy as np\n>>> arr = np.random.rand(100, 8, 8)\n>>> resultado = analise_shape(arr)\n>>> isinstance(resultado, dict)\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "p2": {
          "name": "p2",
          "points": 1.5
        },
        "p3": {
          "name": "p3",
          "points": 1.5
        },
        "p4": {
          "name": "p4",
          "points": 1.5
        },
        "p5": {
          "name": "p5",
          "points": 1
        },
        "p6": {
          "name": "p6",
          "points": 1
        },
        "p7": {
          "name": "p7",
          "points": 1.5
        },
        "p8": {
          "name": "p8",
          "points": 1
        }
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}